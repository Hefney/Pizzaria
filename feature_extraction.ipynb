{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Show all columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = pd.read_csv(\"vocab.csv\")\n",
    "\n",
    "vocab.loc[-1] = \"unk\"\n",
    "vocab = vocab.reset_index(drop=True)\n",
    "vocab[\"1\"] = \"none\"\n",
    "\n",
    "labels = [None, None, None, None, None, None, None, None, None, pd.Series(\"pizza\"), pd.Series([\"hold\",\"without\",\"no\",\"avoid\",\"hate\",\"ani\"])]\n",
    "csv_file_names = [\"number\", \"size\", \"none\",\"topping\",\"quantity\",\"style\",\"drink_type\",\"container_type\",\"volume\"]\n",
    "\n",
    "for i, csv in zip(range(0,len(labels)), csv_file_names):\n",
    "    labels[i] = pd.read_csv(f\"./labels/{csv}.csv\").iloc[:,0]\n",
    "    labels[i] = labels[i].str.strip()\n",
    "    \n",
    "for i in range(0,11):\n",
    "    if i != 2:\n",
    "        labels[2] = labels[2][~labels[2].isin(labels[i])]\n",
    "        labels[2].dropna(inplace=True)\n",
    "        labels[2] = labels[2].reset_index(drop=True)\n",
    "for i in range(1,11):\n",
    "    labels[i] = labels[i][~labels[i].isin(labels[0])]\n",
    "\n",
    "csv_file_names.extend([\"pizza\",\"neg\"])\n",
    "for i in range(0,11):\n",
    "    vocab.loc[vocab[\"0\"].isin(labels[i]),\"1\"] = csv_file_names[i]\n",
    "vocab.to_csv(\"labeled entities.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(vocab):\n",
    "    vocab_length = vocab.shape[0]\n",
    "    unlabeled_vocab = vocab.to_numpy().reshape(-1,1)\n",
    "    encoder = OneHotEncoder()\n",
    "    encoder = encoder.fit(unlabeled_vocab)\n",
    "    trans_encoded = encoder.transform(unlabeled_vocab)\n",
    "\n",
    "    return vocab_length, encoder, trans_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will be used to get the embedding\n",
    "vocab_length,  vocab_encoder, encoded_vocab = one_hot_encoding(vocab[vocab.columns[0]])\n",
    "# this will be as used in the output \n",
    "labels_length, label_encoder, _ = one_hot_encoding(pd.Series(csv_file_names))\n",
    "encoded_labels = label_encoder.transform(vocab[\"1\"].to_numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use the DataSet class from pytorch to facilitate \n",
    "# batch divisions and data preparation\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, input_indices, labels):\n",
    "        self.input_indices = input_indices\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_indices[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Batch [2/56], Loss: 2.2672531604766846\n",
      "Epoch [1/50], Batch [4/56], Loss: 2.324179172515869\n",
      "Epoch [1/50], Batch [6/56], Loss: 2.130316734313965\n",
      "Epoch [1/50], Batch [8/56], Loss: 2.644019365310669\n",
      "Epoch [1/50], Batch [10/56], Loss: 2.2668538093566895\n",
      "Epoch [1/50], Batch [12/56], Loss: 2.2129769325256348\n",
      "Epoch [1/50], Batch [14/56], Loss: 2.1485743522644043\n",
      "Epoch [1/50], Batch [16/56], Loss: 2.266751766204834\n",
      "Epoch [1/50], Batch [18/56], Loss: 2.1902406215667725\n",
      "Epoch [1/50], Batch [20/56], Loss: 2.252068042755127\n",
      "Epoch [1/50], Batch [22/56], Loss: 2.1068315505981445\n",
      "Epoch [1/50], Batch [24/56], Loss: 2.5176708698272705\n",
      "Epoch [1/50], Batch [26/56], Loss: 2.2976298332214355\n",
      "Epoch [1/50], Batch [28/56], Loss: 2.323777675628662\n",
      "Epoch [1/50], Batch [30/56], Loss: 2.1402435302734375\n",
      "Epoch [1/50], Batch [32/56], Loss: 2.2074384689331055\n",
      "Epoch [1/50], Batch [34/56], Loss: 2.421494483947754\n",
      "Epoch [1/50], Batch [36/56], Loss: 2.214162826538086\n",
      "Epoch [1/50], Batch [38/56], Loss: 2.0683860778808594\n",
      "Epoch [1/50], Batch [40/56], Loss: 2.3311405181884766\n",
      "Epoch [1/50], Batch [42/56], Loss: 2.4462485313415527\n",
      "Epoch [1/50], Batch [44/56], Loss: 2.093123435974121\n",
      "Epoch [1/50], Batch [46/56], Loss: 2.019752025604248\n",
      "Epoch [1/50], Batch [48/56], Loss: 2.107973575592041\n",
      "Epoch [1/50], Batch [50/56], Loss: 2.149205207824707\n",
      "Epoch [1/50], Batch [52/56], Loss: 2.1052842140197754\n",
      "Epoch [1/50], Batch [54/56], Loss: 2.4015870094299316\n",
      "Epoch [1/50], Batch [56/56], Loss: 2.8099915981292725\n",
      "Epoch [1/50] completed, Loss: 2.8099915981292725\n",
      "Epoch [2/50], Batch [2/56], Loss: 2.2536044120788574\n",
      "Epoch [2/50], Batch [4/56], Loss: 2.310091972351074\n",
      "Epoch [2/50], Batch [6/56], Loss: 2.116934299468994\n",
      "Epoch [2/50], Batch [8/56], Loss: 2.6417343616485596\n",
      "Epoch [2/50], Batch [10/56], Loss: 2.2655279636383057\n",
      "Epoch [2/50], Batch [12/56], Loss: 2.1967713832855225\n",
      "Epoch [2/50], Batch [14/56], Loss: 2.1482396125793457\n",
      "Epoch [2/50], Batch [16/56], Loss: 2.2654900550842285\n",
      "Epoch [2/50], Batch [18/56], Loss: 2.1749327182769775\n",
      "Epoch [2/50], Batch [20/56], Loss: 2.247340679168701\n",
      "Epoch [2/50], Batch [22/56], Loss: 2.0961155891418457\n",
      "Epoch [2/50], Batch [24/56], Loss: 2.5232622623443604\n",
      "Epoch [2/50], Batch [26/56], Loss: 2.2858827114105225\n",
      "Epoch [2/50], Batch [28/56], Loss: 2.3175125122070312\n",
      "Epoch [2/50], Batch [30/56], Loss: 2.131981372833252\n",
      "Epoch [2/50], Batch [32/56], Loss: 2.19338321685791\n",
      "Epoch [2/50], Batch [34/56], Loss: 2.4135966300964355\n",
      "Epoch [2/50], Batch [36/56], Loss: 2.2069716453552246\n",
      "Epoch [2/50], Batch [38/56], Loss: 2.064891815185547\n",
      "Epoch [2/50], Batch [40/56], Loss: 2.3232624530792236\n",
      "Epoch [2/50], Batch [42/56], Loss: 2.443779230117798\n",
      "Epoch [2/50], Batch [44/56], Loss: 2.0776195526123047\n",
      "Epoch [2/50], Batch [46/56], Loss: 2.013080596923828\n",
      "Epoch [2/50], Batch [48/56], Loss: 2.0957374572753906\n",
      "Epoch [2/50], Batch [50/56], Loss: 2.143430233001709\n",
      "Epoch [2/50], Batch [52/56], Loss: 2.099320650100708\n",
      "Epoch [2/50], Batch [54/56], Loss: 2.3935816287994385\n",
      "Epoch [2/50], Batch [56/56], Loss: 2.8085384368896484\n",
      "Epoch [2/50] completed, Loss: 2.8085384368896484\n",
      "Epoch [3/50], Batch [2/56], Loss: 2.2428369522094727\n",
      "Epoch [3/50], Batch [4/56], Loss: 2.299483299255371\n",
      "Epoch [3/50], Batch [6/56], Loss: 2.1065514087677\n",
      "Epoch [3/50], Batch [8/56], Loss: 2.6400108337402344\n",
      "Epoch [3/50], Batch [10/56], Loss: 2.264488697052002\n",
      "Epoch [3/50], Batch [12/56], Loss: 2.1839869022369385\n",
      "Epoch [3/50], Batch [14/56], Loss: 2.1480677127838135\n",
      "Epoch [3/50], Batch [16/56], Loss: 2.2644569873809814\n",
      "Epoch [3/50], Batch [18/56], Loss: 2.162602186203003\n",
      "Epoch [3/50], Batch [20/56], Loss: 2.243295431137085\n",
      "Epoch [3/50], Batch [22/56], Loss: 2.0872883796691895\n",
      "Epoch [3/50], Batch [24/56], Loss: 2.5280706882476807\n",
      "Epoch [3/50], Batch [26/56], Loss: 2.2758238315582275\n",
      "Epoch [3/50], Batch [28/56], Loss: 2.3120696544647217\n",
      "Epoch [3/50], Batch [30/56], Loss: 2.1247825622558594\n",
      "Epoch [3/50], Batch [32/56], Loss: 2.180795669555664\n",
      "Epoch [3/50], Batch [34/56], Loss: 2.406562328338623\n",
      "Epoch [3/50], Batch [36/56], Loss: 2.2004261016845703\n",
      "Epoch [3/50], Batch [38/56], Loss: 2.061723470687866\n",
      "Epoch [3/50], Batch [40/56], Loss: 2.315903425216675\n",
      "Epoch [3/50], Batch [42/56], Loss: 2.4416000843048096\n",
      "Epoch [3/50], Batch [44/56], Loss: 2.0630576610565186\n",
      "Epoch [3/50], Batch [46/56], Loss: 2.0068628787994385\n",
      "Epoch [3/50], Batch [48/56], Loss: 2.0841991901397705\n",
      "Epoch [3/50], Batch [50/56], Loss: 2.1379308700561523\n",
      "Epoch [3/50], Batch [52/56], Loss: 2.0937247276306152\n",
      "Epoch [3/50], Batch [54/56], Loss: 2.3859024047851562\n",
      "Epoch [3/50], Batch [56/56], Loss: 2.807161808013916\n",
      "Epoch [3/50] completed, Loss: 2.807161808013916\n",
      "Epoch [4/50], Batch [2/56], Loss: 2.2325665950775146\n",
      "Epoch [4/50], Batch [4/56], Loss: 2.289252281188965\n",
      "Epoch [4/50], Batch [6/56], Loss: 2.096615791320801\n",
      "Epoch [4/50], Batch [8/56], Loss: 2.6382968425750732\n",
      "Epoch [4/50], Batch [10/56], Loss: 2.263524055480957\n",
      "Epoch [4/50], Batch [12/56], Loss: 2.1716911792755127\n",
      "Epoch [4/50], Batch [14/56], Loss: 2.14793062210083\n",
      "Epoch [4/50], Batch [16/56], Loss: 2.2634975910186768\n",
      "Epoch [4/50], Batch [18/56], Loss: 2.1508142948150635\n",
      "Epoch [4/50], Batch [20/56], Loss: 2.23937726020813\n",
      "Epoch [4/50], Batch [22/56], Loss: 2.0788116455078125\n",
      "Epoch [4/50], Batch [24/56], Loss: 2.5327537059783936\n",
      "Epoch [4/50], Batch [26/56], Loss: 2.266141891479492\n",
      "Epoch [4/50], Batch [28/56], Loss: 2.306830883026123\n",
      "Epoch [4/50], Batch [30/56], Loss: 2.117889165878296\n",
      "Epoch [4/50], Batch [32/56], Loss: 2.168586254119873\n",
      "Epoch [4/50], Batch [34/56], Loss: 2.3998208045959473\n",
      "Epoch [4/50], Batch [36/56], Loss: 2.1940574645996094\n",
      "Epoch [4/50], Batch [38/56], Loss: 2.058690071105957\n",
      "Epoch [4/50], Batch [40/56], Loss: 2.308737277984619\n",
      "Epoch [4/50], Batch [42/56], Loss: 2.4395852088928223\n",
      "Epoch [4/50], Batch [44/56], Loss: 2.04888916015625\n",
      "Epoch [4/50], Batch [46/56], Loss: 2.0008552074432373\n",
      "Epoch [4/50], Batch [48/56], Loss: 2.073009967803955\n",
      "Epoch [4/50], Batch [50/56], Loss: 2.132570505142212\n",
      "Epoch [4/50], Batch [52/56], Loss: 2.0883371829986572\n",
      "Epoch [4/50], Batch [54/56], Loss: 2.3783841133117676\n",
      "Epoch [4/50], Batch [56/56], Loss: 2.8058345317840576\n",
      "Epoch [4/50] completed, Loss: 2.8058345317840576\n",
      "Epoch [5/50], Batch [2/56], Loss: 2.2225658893585205\n",
      "Epoch [5/50], Batch [4/56], Loss: 2.2791953086853027\n",
      "Epoch [5/50], Batch [6/56], Loss: 2.086916446685791\n",
      "Epoch [5/50], Batch [8/56], Loss: 2.636582374572754\n",
      "Epoch [5/50], Batch [10/56], Loss: 2.2626235485076904\n",
      "Epoch [5/50], Batch [12/56], Loss: 2.1596460342407227\n",
      "Epoch [5/50], Batch [14/56], Loss: 2.1478259563446045\n",
      "Epoch [5/50], Batch [16/56], Loss: 2.2626023292541504\n",
      "Epoch [5/50], Batch [18/56], Loss: 2.1393401622772217\n",
      "Epoch [5/50], Batch [20/56], Loss: 2.235534191131592\n",
      "Epoch [5/50], Batch [22/56], Loss: 2.0705296993255615\n",
      "Epoch [5/50], Batch [24/56], Loss: 2.5373854637145996\n",
      "Epoch [5/50], Batch [26/56], Loss: 2.2566821575164795\n",
      "Epoch [5/50], Batch [28/56], Loss: 2.3017170429229736\n",
      "Epoch [5/50], Batch [30/56], Loss: 2.111196517944336\n",
      "Epoch [5/50], Batch [32/56], Loss: 2.1565966606140137\n",
      "Epoch [5/50], Batch [34/56], Loss: 2.393280029296875\n",
      "Epoch [5/50], Batch [36/56], Loss: 2.187788963317871\n",
      "Epoch [5/50], Batch [38/56], Loss: 2.0557546615600586\n",
      "Epoch [5/50], Batch [40/56], Loss: 2.301696300506592\n",
      "Epoch [5/50], Batch [42/56], Loss: 2.43770694732666\n",
      "Epoch [5/50], Batch [44/56], Loss: 2.034986972808838\n",
      "Epoch [5/50], Batch [46/56], Loss: 1.9949986934661865\n",
      "Epoch [5/50], Batch [48/56], Loss: 2.062077522277832\n",
      "Epoch [5/50], Batch [50/56], Loss: 2.127309799194336\n",
      "Epoch [5/50], Batch [52/56], Loss: 2.0831122398376465\n",
      "Epoch [5/50], Batch [54/56], Loss: 2.370978355407715\n",
      "Epoch [5/50], Batch [56/56], Loss: 2.8045473098754883\n",
      "Epoch [5/50] completed, Loss: 2.8045473098754883\n",
      "Epoch [6/50], Batch [2/56], Loss: 2.212766408920288\n",
      "Epoch [6/50], Batch [4/56], Loss: 2.26924991607666\n",
      "Epoch [6/50], Batch [6/56], Loss: 2.0773890018463135\n",
      "Epoch [6/50], Batch [8/56], Loss: 2.6348657608032227\n",
      "Epoch [6/50], Batch [10/56], Loss: 2.2617835998535156\n",
      "Epoch [6/50], Batch [12/56], Loss: 2.147778034210205\n",
      "Epoch [6/50], Batch [14/56], Loss: 2.147752285003662\n",
      "Epoch [6/50], Batch [16/56], Loss: 2.2617669105529785\n",
      "Epoch [6/50], Batch [18/56], Loss: 2.1281065940856934\n",
      "Epoch [6/50], Batch [20/56], Loss: 2.2317490577697754\n",
      "Epoch [6/50], Batch [22/56], Loss: 2.0623927116394043\n",
      "Epoch [6/50], Batch [24/56], Loss: 2.5419886112213135\n",
      "Epoch [6/50], Batch [26/56], Loss: 2.24739146232605\n",
      "Epoch [6/50], Batch [28/56], Loss: 2.296701192855835\n",
      "Epoch [6/50], Batch [30/56], Loss: 2.1046676635742188\n",
      "Epoch [6/50], Batch [32/56], Loss: 2.144770622253418\n",
      "Epoch [6/50], Batch [34/56], Loss: 2.386906385421753\n",
      "Epoch [6/50], Batch [36/56], Loss: 2.181593418121338\n",
      "Epoch [6/50], Batch [38/56], Loss: 2.052903413772583\n",
      "Epoch [6/50], Batch [40/56], Loss: 2.2947540283203125\n",
      "Epoch [6/50], Batch [42/56], Loss: 2.435953378677368\n",
      "Epoch [6/50], Batch [44/56], Loss: 2.021299123764038\n",
      "Epoch [6/50], Batch [46/56], Loss: 1.9892687797546387\n",
      "Epoch [6/50], Batch [48/56], Loss: 2.0513622760772705\n",
      "Epoch [6/50], Batch [50/56], Loss: 2.1221323013305664\n",
      "Epoch [6/50], Batch [52/56], Loss: 2.078030824661255\n",
      "Epoch [6/50], Batch [54/56], Loss: 2.3636622428894043\n",
      "Epoch [6/50], Batch [56/56], Loss: 2.803295850753784\n",
      "Epoch [6/50] completed, Loss: 2.803295850753784\n",
      "Epoch [7/50], Batch [2/56], Loss: 2.2031376361846924\n",
      "Epoch [7/50], Batch [4/56], Loss: 2.2593908309936523\n",
      "Epoch [7/50], Batch [6/56], Loss: 2.0680055618286133\n",
      "Epoch [7/50], Batch [8/56], Loss: 2.633145570755005\n",
      "Epoch [7/50], Batch [10/56], Loss: 2.2610015869140625\n",
      "Epoch [7/50], Batch [12/56], Loss: 2.136054039001465\n",
      "Epoch [7/50], Batch [14/56], Loss: 2.1477091312408447\n",
      "Epoch [7/50], Batch [16/56], Loss: 2.260989189147949\n",
      "Epoch [7/50], Batch [18/56], Loss: 2.117079257965088\n",
      "Epoch [7/50], Batch [20/56], Loss: 2.2280144691467285\n",
      "Epoch [7/50], Batch [22/56], Loss: 2.054377794265747\n",
      "Epoch [7/50], Batch [24/56], Loss: 2.546574115753174\n",
      "Epoch [7/50], Batch [26/56], Loss: 2.238245725631714\n",
      "Epoch [7/50], Batch [28/56], Loss: 2.2917702198028564\n",
      "Epoch [7/50], Batch [30/56], Loss: 2.0982847213745117\n",
      "Epoch [7/50], Batch [32/56], Loss: 2.133082389831543\n",
      "Epoch [7/50], Batch [34/56], Loss: 2.3806827068328857\n",
      "Epoch [7/50], Batch [36/56], Loss: 2.1754581928253174\n",
      "Epoch [7/50], Batch [38/56], Loss: 2.0501294136047363\n",
      "Epoch [7/50], Batch [40/56], Loss: 2.2878966331481934\n",
      "Epoch [7/50], Batch [42/56], Loss: 2.4343178272247314\n",
      "Epoch [7/50], Batch [44/56], Loss: 2.0078001022338867\n",
      "Epoch [7/50], Batch [46/56], Loss: 1.9836536645889282\n",
      "Epoch [7/50], Batch [48/56], Loss: 2.0408425331115723\n",
      "Epoch [7/50], Batch [50/56], Loss: 2.1170296669006348\n",
      "Epoch [7/50], Batch [52/56], Loss: 2.0730812549591064\n",
      "Epoch [7/50], Batch [54/56], Loss: 2.3564248085021973\n",
      "Epoch [7/50], Batch [56/56], Loss: 2.8020777702331543\n",
      "Epoch [7/50] completed, Loss: 2.8020777702331543\n",
      "Epoch [8/50], Batch [2/56], Loss: 2.1936631202697754\n",
      "Epoch [8/50], Batch [4/56], Loss: 2.249603509902954\n",
      "Epoch [8/50], Batch [6/56], Loss: 2.058750629425049\n",
      "Epoch [8/50], Batch [8/56], Loss: 2.6314215660095215\n",
      "Epoch [8/50], Batch [10/56], Loss: 2.2602758407592773\n",
      "Epoch [8/50], Batch [12/56], Loss: 2.1244571208953857\n",
      "Epoch [8/50], Batch [14/56], Loss: 2.1476964950561523\n",
      "Epoch [8/50], Batch [16/56], Loss: 2.260267972946167\n",
      "Epoch [8/50], Batch [18/56], Loss: 2.1062395572662354\n",
      "Epoch [8/50], Batch [20/56], Loss: 2.2243261337280273\n",
      "Epoch [8/50], Batch [22/56], Loss: 2.0464725494384766\n",
      "Epoch [8/50], Batch [24/56], Loss: 2.5511467456817627\n",
      "Epoch [8/50], Batch [26/56], Loss: 2.229231357574463\n",
      "Epoch [8/50], Batch [28/56], Loss: 2.286916732788086\n",
      "Epoch [8/50], Batch [30/56], Loss: 2.0920372009277344\n",
      "Epoch [8/50], Batch [32/56], Loss: 2.121516704559326\n",
      "Epoch [8/50], Batch [34/56], Loss: 2.374598503112793\n",
      "Epoch [8/50], Batch [36/56], Loss: 2.169375419616699\n",
      "Epoch [8/50], Batch [38/56], Loss: 2.0474281311035156\n",
      "Epoch [8/50], Batch [40/56], Loss: 2.281116485595703\n",
      "Epoch [8/50], Batch [42/56], Loss: 2.432796001434326\n",
      "Epoch [8/50], Batch [44/56], Loss: 1.994474172592163\n",
      "Epoch [8/50], Batch [46/56], Loss: 1.9781454801559448\n",
      "Epoch [8/50], Batch [48/56], Loss: 2.030505657196045\n",
      "Epoch [8/50], Batch [50/56], Loss: 2.1119964122772217\n",
      "Epoch [8/50], Batch [52/56], Loss: 2.0682570934295654\n",
      "Epoch [8/50], Batch [54/56], Loss: 2.349259376525879\n",
      "Epoch [8/50], Batch [56/56], Loss: 2.8008906841278076\n",
      "Epoch [8/50] completed, Loss: 2.8008906841278076\n",
      "Epoch [9/50], Batch [2/56], Loss: 2.184332847595215\n",
      "Epoch [9/50], Batch [4/56], Loss: 2.2398808002471924\n",
      "Epoch [9/50], Batch [6/56], Loss: 2.049614906311035\n",
      "Epoch [9/50], Batch [8/56], Loss: 2.6296944618225098\n",
      "Epoch [9/50], Batch [10/56], Loss: 2.2596054077148438\n",
      "Epoch [9/50], Batch [12/56], Loss: 2.112976312637329\n",
      "Epoch [9/50], Batch [14/56], Loss: 2.147714614868164\n",
      "Epoch [9/50], Batch [16/56], Loss: 2.259601593017578\n",
      "Epoch [9/50], Batch [18/56], Loss: 2.0955758094787598\n",
      "Epoch [9/50], Batch [20/56], Loss: 2.2206809520721436\n",
      "Epoch [9/50], Batch [22/56], Loss: 2.0386693477630615\n",
      "Epoch [9/50], Batch [24/56], Loss: 2.555710554122925\n",
      "Epoch [9/50], Batch [26/56], Loss: 2.220339059829712\n",
      "Epoch [9/50], Batch [28/56], Loss: 2.2821362018585205\n",
      "Epoch [9/50], Batch [30/56], Loss: 2.0859179496765137\n",
      "Epoch [9/50], Batch [32/56], Loss: 2.11006498336792\n",
      "Epoch [9/50], Batch [34/56], Loss: 2.368647575378418\n",
      "Epoch [9/50], Batch [36/56], Loss: 2.163341522216797\n",
      "Epoch [9/50], Batch [38/56], Loss: 2.044796943664551\n",
      "Epoch [9/50], Batch [40/56], Loss: 2.274409055709839\n",
      "Epoch [9/50], Batch [42/56], Loss: 2.4313838481903076\n",
      "Epoch [9/50], Batch [44/56], Loss: 1.9813103675842285\n",
      "Epoch [9/50], Batch [46/56], Loss: 1.972739815711975\n",
      "Epoch [9/50], Batch [48/56], Loss: 2.0203418731689453\n",
      "Epoch [9/50], Batch [50/56], Loss: 2.1070291996002197\n",
      "Epoch [9/50], Batch [52/56], Loss: 2.063554048538208\n",
      "Epoch [9/50], Batch [54/56], Loss: 2.342161178588867\n",
      "Epoch [9/50], Batch [56/56], Loss: 2.799734115600586\n",
      "Epoch [9/50] completed, Loss: 2.799734115600586\n",
      "Epoch [10/50], Batch [2/56], Loss: 2.1751396656036377\n",
      "Epoch [10/50], Batch [4/56], Loss: 2.2302169799804688\n",
      "Epoch [10/50], Batch [6/56], Loss: 2.0405919551849365\n",
      "Epoch [10/50], Batch [8/56], Loss: 2.6279640197753906\n",
      "Epoch [10/50], Batch [10/56], Loss: 2.258988857269287\n",
      "Epoch [10/50], Batch [12/56], Loss: 2.10160493850708\n",
      "Epoch [10/50], Batch [14/56], Loss: 2.147763252258301\n",
      "Epoch [10/50], Batch [16/56], Loss: 2.2589893341064453\n",
      "Epoch [10/50], Batch [18/56], Loss: 2.085078716278076\n",
      "Epoch [10/50], Batch [20/56], Loss: 2.21707820892334\n",
      "Epoch [10/50], Batch [22/56], Loss: 2.03096342086792\n",
      "Epoch [10/50], Batch [24/56], Loss: 2.560267448425293\n",
      "Epoch [10/50], Batch [26/56], Loss: 2.2115631103515625\n",
      "Epoch [10/50], Batch [28/56], Loss: 2.2774250507354736\n",
      "Epoch [10/50], Batch [30/56], Loss: 2.0799217224121094\n",
      "Epoch [10/50], Batch [32/56], Loss: 2.0987210273742676\n",
      "Epoch [10/50], Batch [34/56], Loss: 2.362823486328125\n",
      "Epoch [10/50], Batch [36/56], Loss: 2.1573543548583984\n",
      "Epoch [10/50], Batch [38/56], Loss: 2.042234420776367\n",
      "Epoch [10/50], Batch [40/56], Loss: 2.267770290374756\n",
      "Epoch [10/50], Batch [42/56], Loss: 2.4300785064697266\n",
      "Epoch [10/50], Batch [44/56], Loss: 1.9683022499084473\n",
      "Epoch [10/50], Batch [46/56], Loss: 1.9674330949783325\n",
      "Epoch [10/50], Batch [48/56], Loss: 2.010344982147217\n",
      "Epoch [10/50], Batch [50/56], Loss: 2.102125883102417\n",
      "Epoch [10/50], Batch [52/56], Loss: 2.0589685440063477\n",
      "Epoch [10/50], Batch [54/56], Loss: 2.3351268768310547\n",
      "Epoch [10/50], Batch [56/56], Loss: 2.7986066341400146\n",
      "Epoch [10/50] completed, Loss: 2.7986066341400146\n",
      "Epoch [11/50], Batch [2/56], Loss: 2.1660783290863037\n",
      "Epoch [11/50], Batch [4/56], Loss: 2.220608949661255\n",
      "Epoch [11/50], Batch [6/56], Loss: 2.031677722930908\n",
      "Epoch [11/50], Batch [8/56], Loss: 2.626230239868164\n",
      "Epoch [11/50], Batch [10/56], Loss: 2.2584242820739746\n",
      "Epoch [11/50], Batch [12/56], Loss: 2.0903382301330566\n",
      "Epoch [11/50], Batch [14/56], Loss: 2.1478424072265625\n",
      "Epoch [11/50], Batch [16/56], Loss: 2.2584292888641357\n",
      "Epoch [11/50], Batch [18/56], Loss: 2.0747427940368652\n",
      "Epoch [11/50], Batch [20/56], Loss: 2.2135162353515625\n",
      "Epoch [11/50], Batch [22/56], Loss: 2.0233514308929443\n",
      "Epoch [11/50], Batch [24/56], Loss: 2.5648179054260254\n",
      "Epoch [11/50], Batch [26/56], Loss: 2.2028985023498535\n",
      "Epoch [11/50], Batch [28/56], Loss: 2.272780656814575\n",
      "Epoch [11/50], Batch [30/56], Loss: 2.0740444660186768\n",
      "Epoch [11/50], Batch [32/56], Loss: 2.087480068206787\n",
      "Epoch [11/50], Batch [34/56], Loss: 2.357123374938965\n",
      "Epoch [11/50], Batch [36/56], Loss: 2.151411771774292\n",
      "Epoch [11/50], Batch [38/56], Loss: 2.039738178253174\n",
      "Epoch [11/50], Batch [40/56], Loss: 2.261197328567505\n",
      "Epoch [11/50], Batch [42/56], Loss: 2.428877592086792\n",
      "Epoch [11/50], Batch [44/56], Loss: 1.9554442167282104\n",
      "Epoch [11/50], Batch [46/56], Loss: 1.9622225761413574\n",
      "Epoch [11/50], Batch [48/56], Loss: 2.0005087852478027\n",
      "Epoch [11/50], Batch [50/56], Loss: 2.0972847938537598\n",
      "Epoch [11/50], Batch [52/56], Loss: 2.0544979572296143\n",
      "Epoch [11/50], Batch [54/56], Loss: 2.3281540870666504\n",
      "Epoch [11/50], Batch [56/56], Loss: 2.7975070476531982\n",
      "Epoch [11/50] completed, Loss: 2.7975070476531982\n",
      "Epoch [12/50], Batch [2/56], Loss: 2.1571452617645264\n",
      "Epoch [12/50], Batch [4/56], Loss: 2.211055040359497\n",
      "Epoch [12/50], Batch [6/56], Loss: 2.0228686332702637\n",
      "Epoch [12/50], Batch [8/56], Loss: 2.6244940757751465\n",
      "Epoch [12/50], Batch [10/56], Loss: 2.2579121589660645\n",
      "Epoch [12/50], Batch [12/56], Loss: 2.079172134399414\n",
      "Epoch [12/50], Batch [14/56], Loss: 2.1479530334472656\n",
      "Epoch [12/50], Batch [16/56], Loss: 2.257920980453491\n",
      "Epoch [12/50], Batch [18/56], Loss: 2.0645620822906494\n",
      "Epoch [12/50], Batch [20/56], Loss: 2.209994316101074\n",
      "Epoch [12/50], Batch [22/56], Loss: 2.0158309936523438\n",
      "Epoch [12/50], Batch [24/56], Loss: 2.569364070892334\n",
      "Epoch [12/50], Batch [26/56], Loss: 2.1943421363830566\n",
      "Epoch [12/50], Batch [28/56], Loss: 2.2682015895843506\n",
      "Epoch [12/50], Batch [30/56], Loss: 2.0682830810546875\n",
      "Epoch [12/50], Batch [32/56], Loss: 2.0763392448425293\n",
      "Epoch [12/50], Batch [34/56], Loss: 2.3515424728393555\n",
      "Epoch [12/50], Batch [36/56], Loss: 2.1455135345458984\n",
      "Epoch [12/50], Batch [38/56], Loss: 2.0373072624206543\n",
      "Epoch [12/50], Batch [40/56], Loss: 2.2546887397766113\n",
      "Epoch [12/50], Batch [42/56], Loss: 2.427778720855713\n",
      "Epoch [12/50], Batch [44/56], Loss: 1.9427317380905151\n",
      "Epoch [12/50], Batch [46/56], Loss: 1.9571068286895752\n",
      "Epoch [12/50], Batch [48/56], Loss: 1.9908298254013062\n",
      "Epoch [12/50], Batch [50/56], Loss: 2.0925045013427734\n",
      "Epoch [12/50], Batch [52/56], Loss: 2.050140380859375\n",
      "Epoch [12/50], Batch [54/56], Loss: 2.321241617202759\n",
      "Epoch [12/50], Batch [56/56], Loss: 2.7964351177215576\n",
      "Epoch [12/50] completed, Loss: 2.7964351177215576\n",
      "Epoch [13/50], Batch [2/56], Loss: 2.1483376026153564\n",
      "Epoch [13/50], Batch [4/56], Loss: 2.2015533447265625\n",
      "Epoch [13/50], Batch [6/56], Loss: 2.014162540435791\n",
      "Epoch [13/50], Batch [8/56], Loss: 2.622755527496338\n",
      "Epoch [13/50], Batch [10/56], Loss: 2.257450580596924\n",
      "Epoch [13/50], Batch [12/56], Loss: 2.0681047439575195\n",
      "Epoch [13/50], Batch [14/56], Loss: 2.1480941772460938\n",
      "Epoch [13/50], Batch [16/56], Loss: 2.2574634552001953\n",
      "Epoch [13/50], Batch [18/56], Loss: 2.054533004760742\n",
      "Epoch [13/50], Batch [20/56], Loss: 2.206512451171875\n",
      "Epoch [13/50], Batch [22/56], Loss: 2.0083999633789062\n",
      "Epoch [13/50], Batch [24/56], Loss: 2.5739059448242188\n",
      "Epoch [13/50], Batch [26/56], Loss: 2.1858911514282227\n",
      "Epoch [13/50], Batch [28/56], Loss: 2.263686180114746\n",
      "Epoch [13/50], Batch [30/56], Loss: 2.062634229660034\n",
      "Epoch [13/50], Batch [32/56], Loss: 2.065296173095703\n",
      "Epoch [13/50], Batch [34/56], Loss: 2.346078872680664\n",
      "Epoch [13/50], Batch [36/56], Loss: 2.1396586894989014\n",
      "Epoch [13/50], Batch [38/56], Loss: 2.0349414348602295\n",
      "Epoch [13/50], Batch [40/56], Loss: 2.2482428550720215\n",
      "Epoch [13/50], Batch [42/56], Loss: 2.42677903175354\n",
      "Epoch [13/50], Batch [44/56], Loss: 1.9301618337631226\n",
      "Epoch [13/50], Batch [46/56], Loss: 1.9520843029022217\n",
      "Epoch [13/50], Batch [48/56], Loss: 1.9813035726547241\n",
      "Epoch [13/50], Batch [50/56], Loss: 2.0877842903137207\n",
      "Epoch [13/50], Batch [52/56], Loss: 2.045893907546997\n",
      "Epoch [13/50], Batch [54/56], Loss: 2.314387321472168\n",
      "Epoch [13/50], Batch [56/56], Loss: 2.7953896522521973\n",
      "Epoch [13/50] completed, Loss: 2.7953896522521973\n",
      "Epoch [14/50], Batch [2/56], Loss: 2.1396522521972656\n",
      "Epoch [14/50], Batch [4/56], Loss: 2.192103385925293\n",
      "Epoch [14/50], Batch [6/56], Loss: 2.005556583404541\n",
      "Epoch [14/50], Batch [8/56], Loss: 2.6210153102874756\n",
      "Epoch [14/50], Batch [10/56], Loss: 2.2570390701293945\n",
      "Epoch [14/50], Batch [12/56], Loss: 2.057133674621582\n",
      "Epoch [14/50], Batch [14/56], Loss: 2.1482672691345215\n",
      "Epoch [14/50], Batch [16/56], Loss: 2.2570555210113525\n",
      "Epoch [14/50], Batch [18/56], Loss: 2.044651985168457\n",
      "Epoch [14/50], Batch [20/56], Loss: 2.2030696868896484\n",
      "Epoch [14/50], Batch [22/56], Loss: 2.0010573863983154\n",
      "Epoch [14/50], Batch [24/56], Loss: 2.578443765640259\n",
      "Epoch [14/50], Batch [26/56], Loss: 2.1775429248809814\n",
      "Epoch [14/50], Batch [28/56], Loss: 2.259232997894287\n",
      "Epoch [14/50], Batch [30/56], Loss: 2.057096004486084\n",
      "Epoch [14/50], Batch [32/56], Loss: 2.054348945617676\n",
      "Epoch [14/50], Batch [34/56], Loss: 2.340728759765625\n",
      "Epoch [14/50], Batch [36/56], Loss: 2.133847713470459\n",
      "Epoch [14/50], Batch [38/56], Loss: 2.0326390266418457\n",
      "Epoch [14/50], Batch [40/56], Loss: 2.2418580055236816\n",
      "Epoch [14/50], Batch [42/56], Loss: 2.425877094268799\n",
      "Epoch [14/50], Batch [44/56], Loss: 1.9177314043045044\n",
      "Epoch [14/50], Batch [46/56], Loss: 1.9471535682678223\n",
      "Epoch [14/50], Batch [48/56], Loss: 1.9719264507293701\n",
      "Epoch [14/50], Batch [50/56], Loss: 2.0831236839294434\n",
      "Epoch [14/50], Batch [52/56], Loss: 2.041757106781006\n",
      "Epoch [14/50], Batch [54/56], Loss: 2.3075904846191406\n",
      "Epoch [14/50], Batch [56/56], Loss: 2.794370174407959\n",
      "Epoch [14/50] completed, Loss: 2.794370174407959\n",
      "Epoch [15/50], Batch [2/56], Loss: 2.1310875415802\n",
      "Epoch [15/50], Batch [4/56], Loss: 2.182704448699951\n",
      "Epoch [15/50], Batch [6/56], Loss: 1.9970500469207764\n",
      "Epoch [15/50], Batch [8/56], Loss: 2.6192736625671387\n",
      "Epoch [15/50], Batch [10/56], Loss: 2.256675958633423\n",
      "Epoch [15/50], Batch [12/56], Loss: 2.0462570190429688\n",
      "Epoch [15/50], Batch [14/56], Loss: 2.1484718322753906\n",
      "Epoch [15/50], Batch [16/56], Loss: 2.2566967010498047\n",
      "Epoch [15/50], Batch [18/56], Loss: 2.034914970397949\n",
      "Epoch [15/50], Batch [20/56], Loss: 2.1996660232543945\n",
      "Epoch [15/50], Batch [22/56], Loss: 1.9938017129898071\n",
      "Epoch [15/50], Batch [24/56], Loss: 2.5829784870147705\n",
      "Epoch [15/50], Batch [26/56], Loss: 2.169295072555542\n",
      "Epoch [15/50], Batch [28/56], Loss: 2.254840850830078\n",
      "Epoch [15/50], Batch [30/56], Loss: 2.051666021347046\n",
      "Epoch [15/50], Batch [32/56], Loss: 2.0434954166412354\n",
      "Epoch [15/50], Batch [34/56], Loss: 2.3354897499084473\n",
      "Epoch [15/50], Batch [36/56], Loss: 2.128079652786255\n",
      "Epoch [15/50], Batch [38/56], Loss: 2.030399799346924\n",
      "Epoch [15/50], Batch [40/56], Loss: 2.2355334758758545\n",
      "Epoch [15/50], Batch [42/56], Loss: 2.425070285797119\n",
      "Epoch [15/50], Batch [44/56], Loss: 1.9054375886917114\n",
      "Epoch [15/50], Batch [46/56], Loss: 1.9423134326934814\n",
      "Epoch [15/50], Batch [48/56], Loss: 1.9626954793930054\n",
      "Epoch [15/50], Batch [50/56], Loss: 2.078521728515625\n",
      "Epoch [15/50], Batch [52/56], Loss: 2.0377283096313477\n",
      "Epoch [15/50], Batch [54/56], Loss: 2.3008501529693604\n",
      "Epoch [15/50], Batch [56/56], Loss: 2.7933757305145264\n",
      "Epoch [15/50] completed, Loss: 2.7933757305145264\n",
      "Epoch [16/50], Batch [2/56], Loss: 2.122640609741211\n",
      "Epoch [16/50], Batch [4/56], Loss: 2.1733555793762207\n",
      "Epoch [16/50], Batch [6/56], Loss: 1.9886406660079956\n",
      "Epoch [16/50], Batch [8/56], Loss: 2.6175315380096436\n",
      "Epoch [16/50], Batch [10/56], Loss: 2.256361246109009\n",
      "Epoch [16/50], Batch [12/56], Loss: 2.035473346710205\n",
      "Epoch [16/50], Batch [14/56], Loss: 2.1487081050872803\n",
      "Epoch [16/50], Batch [16/56], Loss: 2.2563858032226562\n",
      "Epoch [16/50], Batch [18/56], Loss: 2.0253195762634277\n",
      "Epoch [16/50], Batch [20/56], Loss: 2.196300983428955\n",
      "Epoch [16/50], Batch [22/56], Loss: 1.9866323471069336\n",
      "Epoch [16/50], Batch [24/56], Loss: 2.587510108947754\n",
      "Epoch [16/50], Batch [26/56], Loss: 2.1611461639404297\n",
      "Epoch [16/50], Batch [28/56], Loss: 2.250509262084961\n",
      "Epoch [16/50], Batch [30/56], Loss: 2.046341896057129\n",
      "Epoch [16/50], Batch [32/56], Loss: 2.0327348709106445\n",
      "Epoch [16/50], Batch [34/56], Loss: 2.330359935760498\n",
      "Epoch [16/50], Batch [36/56], Loss: 2.1223556995391846\n",
      "Epoch [16/50], Batch [38/56], Loss: 2.0282232761383057\n",
      "Epoch [16/50], Batch [40/56], Loss: 2.2292683124542236\n",
      "Epoch [16/50], Batch [42/56], Loss: 2.4243571758270264\n",
      "Epoch [16/50], Batch [44/56], Loss: 1.8932784795761108\n",
      "Epoch [16/50], Batch [46/56], Loss: 1.937563419342041\n",
      "Epoch [16/50], Batch [48/56], Loss: 1.9536076784133911\n",
      "Epoch [16/50], Batch [50/56], Loss: 2.0739781856536865\n",
      "Epoch [16/50], Batch [52/56], Loss: 2.0338058471679688\n",
      "Epoch [16/50], Batch [54/56], Loss: 2.29416561126709\n",
      "Epoch [16/50], Batch [56/56], Loss: 2.7924060821533203\n",
      "Epoch [16/50] completed, Loss: 2.7924060821533203\n",
      "Epoch [17/50], Batch [2/56], Loss: 2.1143107414245605\n",
      "Epoch [17/50], Batch [4/56], Loss: 2.164057493209839\n",
      "Epoch [17/50], Batch [6/56], Loss: 1.9803270101547241\n",
      "Epoch [17/50], Batch [8/56], Loss: 2.615788459777832\n",
      "Epoch [17/50], Batch [10/56], Loss: 2.2560935020446777\n",
      "Epoch [17/50], Batch [12/56], Loss: 2.0247817039489746\n",
      "Epoch [17/50], Batch [14/56], Loss: 2.1489768028259277\n",
      "Epoch [17/50], Batch [16/56], Loss: 2.2561216354370117\n",
      "Epoch [17/50], Batch [18/56], Loss: 2.0158629417419434\n",
      "Epoch [17/50], Batch [20/56], Loss: 2.19297456741333\n",
      "Epoch [17/50], Batch [22/56], Loss: 1.979548454284668\n",
      "Epoch [17/50], Batch [24/56], Loss: 2.592038631439209\n",
      "Epoch [17/50], Batch [26/56], Loss: 2.1530940532684326\n",
      "Epoch [17/50], Batch [28/56], Loss: 2.24623703956604\n",
      "Epoch [17/50], Batch [30/56], Loss: 2.0411219596862793\n",
      "Epoch [17/50], Batch [32/56], Loss: 2.022066116333008\n",
      "Epoch [17/50], Batch [34/56], Loss: 2.325336456298828\n",
      "Epoch [17/50], Batch [36/56], Loss: 2.11667537689209\n",
      "Epoch [17/50], Batch [38/56], Loss: 2.026108741760254\n",
      "Epoch [17/50], Batch [40/56], Loss: 2.2230618000030518\n",
      "Epoch [17/50], Batch [42/56], Loss: 2.4237353801727295\n",
      "Epoch [17/50], Batch [44/56], Loss: 1.8812519311904907\n",
      "Epoch [17/50], Batch [46/56], Loss: 1.9329020977020264\n",
      "Epoch [17/50], Batch [48/56], Loss: 1.9446609020233154\n",
      "Epoch [17/50], Batch [50/56], Loss: 2.0694925785064697\n",
      "Epoch [17/50], Batch [52/56], Loss: 2.029989242553711\n",
      "Epoch [17/50], Batch [54/56], Loss: 2.287536144256592\n",
      "Epoch [17/50], Batch [56/56], Loss: 2.7914605140686035\n",
      "Epoch [17/50] completed, Loss: 2.7914605140686035\n",
      "Epoch [18/50], Batch [2/56], Loss: 2.1060950756073\n",
      "Epoch [18/50], Batch [4/56], Loss: 2.1548094749450684\n",
      "Epoch [18/50], Batch [6/56], Loss: 1.9721086025238037\n",
      "Epoch [18/50], Batch [8/56], Loss: 2.614046096801758\n",
      "Epoch [18/50], Batch [10/56], Loss: 2.2558720111846924\n",
      "Epoch [18/50], Batch [12/56], Loss: 2.014181613922119\n",
      "Epoch [18/50], Batch [14/56], Loss: 2.149277448654175\n",
      "Epoch [18/50], Batch [16/56], Loss: 2.255904197692871\n",
      "Epoch [18/50], Batch [18/56], Loss: 2.006542444229126\n",
      "Epoch [18/50], Batch [20/56], Loss: 2.1896867752075195\n",
      "Epoch [18/50], Batch [22/56], Loss: 1.9725492000579834\n",
      "Epoch [18/50], Batch [24/56], Loss: 2.596564292907715\n",
      "Epoch [18/50], Batch [26/56], Loss: 2.145137310028076\n",
      "Epoch [18/50], Batch [28/56], Loss: 2.242023468017578\n",
      "Epoch [18/50], Batch [30/56], Loss: 2.036003828048706\n",
      "Epoch [18/50], Batch [32/56], Loss: 2.011488199234009\n",
      "Epoch [18/50], Batch [34/56], Loss: 2.3204174041748047\n",
      "Epoch [18/50], Batch [36/56], Loss: 2.111039638519287\n",
      "Epoch [18/50], Batch [38/56], Loss: 2.0240557193756104\n",
      "Epoch [18/50], Batch [40/56], Loss: 2.2169129848480225\n",
      "Epoch [18/50], Batch [42/56], Loss: 2.4232029914855957\n",
      "Epoch [18/50], Batch [44/56], Loss: 1.8693562746047974\n",
      "Epoch [18/50], Batch [46/56], Loss: 1.9283289909362793\n",
      "Epoch [18/50], Batch [48/56], Loss: 1.9358515739440918\n",
      "Epoch [18/50], Batch [50/56], Loss: 2.0650646686553955\n",
      "Epoch [18/50], Batch [52/56], Loss: 2.0262773036956787\n",
      "Epoch [18/50], Batch [54/56], Loss: 2.280961036682129\n",
      "Epoch [18/50], Batch [56/56], Loss: 2.7905385494232178\n",
      "Epoch [18/50] completed, Loss: 2.7905385494232178\n",
      "Epoch [19/50], Batch [2/56], Loss: 2.097993850708008\n",
      "Epoch [19/50], Batch [4/56], Loss: 2.1456122398376465\n",
      "Epoch [19/50], Batch [6/56], Loss: 1.9639842510223389\n",
      "Epoch [19/50], Batch [8/56], Loss: 2.6123039722442627\n",
      "Epoch [19/50], Batch [10/56], Loss: 2.2556960582733154\n",
      "Epoch [19/50], Batch [12/56], Loss: 2.003671646118164\n",
      "Epoch [19/50], Batch [14/56], Loss: 2.149610996246338\n",
      "Epoch [19/50], Batch [16/56], Loss: 2.2557318210601807\n",
      "Epoch [19/50], Batch [18/56], Loss: 1.9973560571670532\n",
      "Epoch [19/50], Batch [20/56], Loss: 2.1864371299743652\n",
      "Epoch [19/50], Batch [22/56], Loss: 1.9656345844268799\n",
      "Epoch [19/50], Batch [24/56], Loss: 2.6010868549346924\n",
      "Epoch [19/50], Batch [26/56], Loss: 2.137274742126465\n",
      "Epoch [19/50], Batch [28/56], Loss: 2.237867593765259\n",
      "Epoch [19/50], Batch [30/56], Loss: 2.0309865474700928\n",
      "Epoch [19/50], Batch [32/56], Loss: 2.001000165939331\n",
      "Epoch [19/50], Batch [34/56], Loss: 2.315600633621216\n",
      "Epoch [19/50], Batch [36/56], Loss: 2.1054484844207764\n",
      "Epoch [19/50], Batch [38/56], Loss: 2.0220632553100586\n",
      "Epoch [19/50], Batch [40/56], Loss: 2.2108213901519775\n",
      "Epoch [19/50], Batch [42/56], Loss: 2.4227590560913086\n",
      "Epoch [19/50], Batch [44/56], Loss: 1.857589840888977\n",
      "Epoch [19/50], Batch [46/56], Loss: 1.9238433837890625\n",
      "Epoch [19/50], Batch [48/56], Loss: 1.9271782636642456\n",
      "Epoch [19/50], Batch [50/56], Loss: 2.0606939792633057\n",
      "Epoch [19/50], Batch [52/56], Loss: 2.0226683616638184\n",
      "Epoch [19/50], Batch [54/56], Loss: 2.274440050125122\n",
      "Epoch [19/50], Batch [56/56], Loss: 2.789639472961426\n",
      "Epoch [19/50] completed, Loss: 2.789639472961426\n",
      "Epoch [20/50], Batch [2/56], Loss: 2.0900039672851562\n",
      "Epoch [20/50], Batch [4/56], Loss: 2.136465549468994\n",
      "Epoch [20/50], Batch [6/56], Loss: 1.955952525138855\n",
      "Epoch [20/50], Batch [8/56], Loss: 2.610562801361084\n",
      "Epoch [20/50], Batch [10/56], Loss: 2.2555644512176514\n",
      "Epoch [20/50], Batch [12/56], Loss: 1.9932513236999512\n",
      "Epoch [20/50], Batch [14/56], Loss: 2.1499767303466797\n",
      "Epoch [20/50], Batch [16/56], Loss: 2.2556040287017822\n",
      "Epoch [20/50], Batch [18/56], Loss: 1.9883008003234863\n",
      "Epoch [20/50], Batch [20/56], Loss: 2.183225631713867\n",
      "Epoch [20/50], Batch [22/56], Loss: 1.958803653717041\n",
      "Epoch [20/50], Batch [24/56], Loss: 2.6056065559387207\n",
      "Epoch [20/50], Batch [26/56], Loss: 2.129504680633545\n",
      "Epoch [20/50], Batch [28/56], Loss: 2.233768939971924\n",
      "Epoch [20/50], Batch [30/56], Loss: 2.0260677337646484\n",
      "Epoch [20/50], Batch [32/56], Loss: 1.9906015396118164\n",
      "Epoch [20/50], Batch [34/56], Loss: 2.3108842372894287\n",
      "Epoch [20/50], Batch [36/56], Loss: 2.099902391433716\n",
      "Epoch [20/50], Batch [38/56], Loss: 2.0201311111450195\n",
      "Epoch [20/50], Batch [40/56], Loss: 2.204786777496338\n",
      "Epoch [20/50], Batch [42/56], Loss: 2.422401189804077\n",
      "Epoch [20/50], Batch [44/56], Loss: 1.8459506034851074\n",
      "Epoch [20/50], Batch [46/56], Loss: 1.9194447994232178\n",
      "Epoch [20/50], Batch [48/56], Loss: 1.9186382293701172\n",
      "Epoch [20/50], Batch [50/56], Loss: 2.056380271911621\n",
      "Epoch [20/50], Batch [52/56], Loss: 2.0191614627838135\n",
      "Epoch [20/50], Batch [54/56], Loss: 2.267972707748413\n",
      "Epoch [20/50], Batch [56/56], Loss: 2.7887630462646484\n",
      "Epoch [20/50] completed, Loss: 2.7887630462646484\n",
      "Epoch [21/50], Batch [2/56], Loss: 2.082125186920166\n",
      "Epoch [21/50], Batch [4/56], Loss: 2.1273694038391113\n",
      "Epoch [21/50], Batch [6/56], Loss: 1.9480125904083252\n",
      "Epoch [21/50], Batch [8/56], Loss: 2.608822822570801\n",
      "Epoch [21/50], Batch [10/56], Loss: 2.255476951599121\n",
      "Epoch [21/50], Batch [12/56], Loss: 1.9829192161560059\n",
      "Epoch [21/50], Batch [14/56], Loss: 2.1503748893737793\n",
      "Epoch [21/50], Batch [16/56], Loss: 2.2555198669433594\n",
      "Epoch [21/50], Batch [18/56], Loss: 1.9793752431869507\n",
      "Epoch [21/50], Batch [20/56], Loss: 2.180051803588867\n",
      "Epoch [21/50], Batch [22/56], Loss: 1.952055811882019\n",
      "Epoch [21/50], Batch [24/56], Loss: 2.6101231575012207\n",
      "Epoch [21/50], Batch [26/56], Loss: 2.121825933456421\n",
      "Epoch [21/50], Batch [28/56], Loss: 2.229726791381836\n",
      "Epoch [21/50], Batch [30/56], Loss: 2.0212466716766357\n",
      "Epoch [21/50], Batch [32/56], Loss: 1.9802913665771484\n",
      "Epoch [21/50], Batch [34/56], Loss: 2.3062658309936523\n",
      "Epoch [21/50], Batch [36/56], Loss: 2.0944018363952637\n",
      "Epoch [21/50], Batch [38/56], Loss: 2.018259286880493\n",
      "Epoch [21/50], Batch [40/56], Loss: 2.198808193206787\n",
      "Epoch [21/50], Batch [42/56], Loss: 2.4221279621124268\n",
      "Epoch [21/50], Batch [44/56], Loss: 1.8344377279281616\n",
      "Epoch [21/50], Batch [46/56], Loss: 1.9151320457458496\n",
      "Epoch [21/50], Batch [48/56], Loss: 1.9102293252944946\n",
      "Epoch [21/50], Batch [50/56], Loss: 2.052123546600342\n",
      "Epoch [21/50], Batch [52/56], Loss: 2.0157558917999268\n",
      "Epoch [21/50], Batch [54/56], Loss: 2.2615585327148438\n",
      "Epoch [21/50], Batch [56/56], Loss: 2.7879080772399902\n",
      "Epoch [21/50] completed, Loss: 2.7879080772399902\n",
      "Epoch [22/50], Batch [2/56], Loss: 2.0743558406829834\n",
      "Epoch [22/50], Batch [4/56], Loss: 2.118323802947998\n",
      "Epoch [22/50], Batch [6/56], Loss: 1.9401638507843018\n",
      "Epoch [22/50], Batch [8/56], Loss: 2.6070847511291504\n",
      "Epoch [22/50], Batch [10/56], Loss: 2.255431890487671\n",
      "Epoch [22/50], Batch [12/56], Loss: 1.9726754426956177\n",
      "Epoch [22/50], Batch [14/56], Loss: 2.150805950164795\n",
      "Epoch [22/50], Batch [16/56], Loss: 2.2554783821105957\n",
      "Epoch [22/50], Batch [18/56], Loss: 1.9705770015716553\n",
      "Epoch [22/50], Batch [20/56], Loss: 2.1769163608551025\n",
      "Epoch [22/50], Batch [22/56], Loss: 1.9453908205032349\n",
      "Epoch [22/50], Batch [24/56], Loss: 2.6146368980407715\n",
      "Epoch [22/50], Batch [26/56], Loss: 2.114237070083618\n",
      "Epoch [22/50], Batch [28/56], Loss: 2.2257401943206787\n",
      "Epoch [22/50], Batch [30/56], Loss: 2.0165209770202637\n",
      "Epoch [22/50], Batch [32/56], Loss: 1.9700690507888794\n",
      "Epoch [22/50], Batch [34/56], Loss: 2.3017444610595703\n",
      "Epoch [22/50], Batch [36/56], Loss: 2.08894681930542\n",
      "Epoch [22/50], Batch [38/56], Loss: 2.016446352005005\n",
      "Epoch [22/50], Batch [40/56], Loss: 2.192885160446167\n",
      "Epoch [22/50], Batch [42/56], Loss: 2.4219377040863037\n",
      "Epoch [22/50], Batch [44/56], Loss: 1.8230493068695068\n",
      "Epoch [22/50], Batch [46/56], Loss: 1.910905122756958\n",
      "Epoch [22/50], Batch [48/56], Loss: 1.9019500017166138\n",
      "Epoch [22/50], Batch [50/56], Loss: 2.0479228496551514\n",
      "Epoch [22/50], Batch [52/56], Loss: 2.0124504566192627\n",
      "Epoch [22/50], Batch [54/56], Loss: 2.2551965713500977\n",
      "Epoch [22/50], Batch [56/56], Loss: 2.7870748043060303\n",
      "Epoch [22/50] completed, Loss: 2.7870748043060303\n",
      "Epoch [23/50], Batch [2/56], Loss: 2.066694736480713\n",
      "Epoch [23/50], Batch [4/56], Loss: 2.1093297004699707\n",
      "Epoch [23/50], Batch [6/56], Loss: 1.9324054718017578\n",
      "Epoch [23/50], Batch [8/56], Loss: 2.605348587036133\n",
      "Epoch [23/50], Batch [10/56], Loss: 2.255429267883301\n",
      "Epoch [23/50], Batch [12/56], Loss: 1.9625191688537598\n",
      "Epoch [23/50], Batch [14/56], Loss: 2.1512696743011475\n",
      "Epoch [23/50], Batch [16/56], Loss: 2.255479335784912\n",
      "Epoch [23/50], Batch [18/56], Loss: 1.9619040489196777\n",
      "Epoch [23/50], Batch [20/56], Loss: 2.1738181114196777\n",
      "Epoch [23/50], Batch [22/56], Loss: 1.9388084411621094\n",
      "Epoch [23/50], Batch [24/56], Loss: 2.6191468238830566\n",
      "Epoch [23/50], Batch [26/56], Loss: 2.1067371368408203\n",
      "Epoch [23/50], Batch [28/56], Loss: 2.221808910369873\n",
      "Epoch [23/50], Batch [30/56], Loss: 2.0118894577026367\n",
      "Epoch [23/50], Batch [32/56], Loss: 1.9599342346191406\n",
      "Epoch [23/50], Batch [34/56], Loss: 2.29731822013855\n",
      "Epoch [23/50], Batch [36/56], Loss: 2.083538055419922\n",
      "Epoch [23/50], Batch [38/56], Loss: 2.014692544937134\n",
      "Epoch [23/50], Batch [40/56], Loss: 2.1870176792144775\n",
      "Epoch [23/50], Batch [42/56], Loss: 2.4218292236328125\n",
      "Epoch [23/50], Batch [44/56], Loss: 1.811784267425537\n",
      "Epoch [23/50], Batch [46/56], Loss: 1.9067628383636475\n",
      "Epoch [23/50], Batch [48/56], Loss: 1.8937978744506836\n",
      "Epoch [23/50], Batch [50/56], Loss: 2.043778419494629\n",
      "Epoch [23/50], Batch [52/56], Loss: 2.009244441986084\n",
      "Epoch [23/50], Batch [54/56], Loss: 2.248887062072754\n",
      "Epoch [23/50], Batch [56/56], Loss: 2.786262035369873\n",
      "Epoch [23/50] completed, Loss: 2.786262035369873\n",
      "Epoch [24/50], Batch [2/56], Loss: 2.059140920639038\n",
      "Epoch [24/50], Batch [4/56], Loss: 2.100386619567871\n",
      "Epoch [24/50], Batch [6/56], Loss: 1.9247362613677979\n",
      "Epoch [24/50], Batch [8/56], Loss: 2.603614330291748\n",
      "Epoch [24/50], Batch [10/56], Loss: 2.2554678916931152\n",
      "Epoch [24/50], Batch [12/56], Loss: 1.9524496793746948\n",
      "Epoch [24/50], Batch [14/56], Loss: 2.151765823364258\n",
      "Epoch [24/50], Batch [16/56], Loss: 2.255521535873413\n",
      "Epoch [24/50], Batch [18/56], Loss: 1.9533545970916748\n",
      "Epoch [24/50], Batch [20/56], Loss: 2.17075777053833\n",
      "Epoch [24/50], Batch [22/56], Loss: 1.9323079586029053\n",
      "Epoch [24/50], Batch [24/56], Loss: 2.6236534118652344\n",
      "Epoch [24/50], Batch [26/56], Loss: 2.099324941635132\n",
      "Epoch [24/50], Batch [28/56], Loss: 2.2179319858551025\n",
      "Epoch [24/50], Batch [30/56], Loss: 2.0073511600494385\n",
      "Epoch [24/50], Batch [32/56], Loss: 1.9498860836029053\n",
      "Epoch [24/50], Batch [34/56], Loss: 2.292984962463379\n",
      "Epoch [24/50], Batch [36/56], Loss: 2.0781755447387695\n",
      "Epoch [24/50], Batch [38/56], Loss: 2.0129969120025635\n",
      "Epoch [24/50], Batch [40/56], Loss: 2.1812052726745605\n",
      "Epoch [24/50], Batch [42/56], Loss: 2.4218006134033203\n",
      "Epoch [24/50], Batch [44/56], Loss: 1.8006409406661987\n",
      "Epoch [24/50], Batch [46/56], Loss: 1.9027047157287598\n",
      "Epoch [24/50], Batch [48/56], Loss: 1.8857712745666504\n",
      "Epoch [24/50], Batch [50/56], Loss: 2.0396900177001953\n",
      "Epoch [24/50], Batch [52/56], Loss: 2.006136894226074\n",
      "Epoch [24/50], Batch [54/56], Loss: 2.2426295280456543\n",
      "Epoch [24/50], Batch [56/56], Loss: 2.7854697704315186\n",
      "Epoch [24/50] completed, Loss: 2.7854697704315186\n",
      "Epoch [25/50], Batch [2/56], Loss: 2.0516932010650635\n",
      "Epoch [25/50], Batch [4/56], Loss: 2.091494560241699\n",
      "Epoch [25/50], Batch [6/56], Loss: 1.9171559810638428\n",
      "Epoch [25/50], Batch [8/56], Loss: 2.6018826961517334\n",
      "Epoch [25/50], Batch [10/56], Loss: 2.255547046661377\n",
      "Epoch [25/50], Batch [12/56], Loss: 1.9424667358398438\n",
      "Epoch [25/50], Batch [14/56], Loss: 2.152294635772705\n",
      "Epoch [25/50], Batch [16/56], Loss: 2.2556040287017822\n",
      "Epoch [25/50], Batch [18/56], Loss: 1.9449270963668823\n",
      "Epoch [25/50], Batch [20/56], Loss: 2.167733669281006\n",
      "Epoch [25/50], Batch [22/56], Loss: 1.9258893728256226\n",
      "Epoch [25/50], Batch [24/56], Loss: 2.6281561851501465\n",
      "Epoch [25/50], Batch [26/56], Loss: 2.0919997692108154\n",
      "Epoch [25/50], Batch [28/56], Loss: 2.214108943939209\n",
      "Epoch [25/50], Batch [30/56], Loss: 2.0029046535491943\n",
      "Epoch [25/50], Batch [32/56], Loss: 1.9399242401123047\n",
      "Epoch [25/50], Batch [34/56], Loss: 2.288743495941162\n",
      "Epoch [25/50], Batch [36/56], Loss: 2.0728602409362793\n",
      "Epoch [25/50], Batch [38/56], Loss: 2.0113587379455566\n",
      "Epoch [25/50], Batch [40/56], Loss: 2.1754467487335205\n",
      "Epoch [25/50], Batch [42/56], Loss: 2.4218506813049316\n",
      "Epoch [25/50], Batch [44/56], Loss: 1.789618968963623\n",
      "Epoch [25/50], Batch [46/56], Loss: 1.8987302780151367\n",
      "Epoch [25/50], Batch [48/56], Loss: 1.877868413925171\n",
      "Epoch [25/50], Batch [50/56], Loss: 2.0356571674346924\n",
      "Epoch [25/50], Batch [52/56], Loss: 2.003126621246338\n",
      "Epoch [25/50], Batch [54/56], Loss: 2.2364230155944824\n",
      "Epoch [25/50], Batch [56/56], Loss: 2.7846970558166504\n",
      "Epoch [25/50] completed, Loss: 2.7846970558166504\n",
      "Epoch [26/50], Batch [2/56], Loss: 2.0443506240844727\n",
      "Epoch [26/50], Batch [4/56], Loss: 2.0826539993286133\n",
      "Epoch [26/50], Batch [6/56], Loss: 1.9096633195877075\n",
      "Epoch [26/50], Batch [8/56], Loss: 2.6001534461975098\n",
      "Epoch [26/50], Batch [10/56], Loss: 2.2556657791137695\n",
      "Epoch [26/50], Batch [12/56], Loss: 1.9325697422027588\n",
      "Epoch [26/50], Batch [14/56], Loss: 2.15285587310791\n",
      "Epoch [26/50], Batch [16/56], Loss: 2.2557263374328613\n",
      "Epoch [26/50], Batch [18/56], Loss: 1.936619758605957\n",
      "Epoch [26/50], Batch [20/56], Loss: 2.1647472381591797\n",
      "Epoch [26/50], Batch [22/56], Loss: 1.9195518493652344\n",
      "Epoch [26/50], Batch [24/56], Loss: 2.6326546669006348\n",
      "Epoch [26/50], Batch [26/56], Loss: 2.0847597122192383\n",
      "Epoch [26/50], Batch [28/56], Loss: 2.2103395462036133\n",
      "Epoch [26/50], Batch [30/56], Loss: 1.9985482692718506\n",
      "Epoch [26/50], Batch [32/56], Loss: 1.9300479888916016\n",
      "Epoch [26/50], Batch [34/56], Loss: 2.2845921516418457\n",
      "Epoch [26/50], Batch [36/56], Loss: 2.067591428756714\n",
      "Epoch [26/50], Batch [38/56], Loss: 2.0097780227661133\n",
      "Epoch [26/50], Batch [40/56], Loss: 2.1697428226470947\n",
      "Epoch [26/50], Batch [42/56], Loss: 2.42197847366333\n",
      "Epoch [26/50], Batch [44/56], Loss: 1.7787163257598877\n",
      "Epoch [26/50], Batch [46/56], Loss: 1.8948384523391724\n",
      "Epoch [26/50], Batch [48/56], Loss: 1.8700876235961914\n",
      "Epoch [26/50], Batch [50/56], Loss: 2.031679391860962\n",
      "Epoch [26/50], Batch [52/56], Loss: 2.0002129077911377\n",
      "Epoch [26/50], Batch [54/56], Loss: 2.2302684783935547\n",
      "Epoch [26/50], Batch [56/56], Loss: 2.7839438915252686\n",
      "Epoch [26/50] completed, Loss: 2.7839438915252686\n",
      "Epoch [27/50], Batch [2/56], Loss: 2.037112236022949\n",
      "Epoch [27/50], Batch [4/56], Loss: 2.0738654136657715\n",
      "Epoch [27/50], Batch [6/56], Loss: 1.9022579193115234\n",
      "Epoch [27/50], Batch [8/56], Loss: 2.5984270572662354\n",
      "Epoch [27/50], Batch [10/56], Loss: 2.255824089050293\n",
      "Epoch [27/50], Batch [12/56], Loss: 1.9227583408355713\n",
      "Epoch [27/50], Batch [14/56], Loss: 2.153449058532715\n",
      "Epoch [27/50], Batch [16/56], Loss: 2.255887508392334\n",
      "Epoch [27/50], Batch [18/56], Loss: 1.9284310340881348\n",
      "Epoch [27/50], Batch [20/56], Loss: 2.161797046661377\n",
      "Epoch [27/50], Batch [22/56], Loss: 1.9132953882217407\n",
      "Epoch [27/50], Batch [24/56], Loss: 2.63714861869812\n",
      "Epoch [27/50], Batch [26/56], Loss: 2.0776047706604004\n",
      "Epoch [27/50], Batch [28/56], Loss: 2.206622362136841\n",
      "Epoch [27/50], Batch [30/56], Loss: 1.9942810535430908\n",
      "Epoch [27/50], Batch [32/56], Loss: 1.920257329940796\n",
      "Epoch [27/50], Batch [34/56], Loss: 2.2805299758911133\n",
      "Epoch [27/50], Batch [36/56], Loss: 2.0623703002929688\n",
      "Epoch [27/50], Batch [38/56], Loss: 2.008254051208496\n",
      "Epoch [27/50], Batch [40/56], Loss: 2.164092540740967\n",
      "Epoch [27/50], Batch [42/56], Loss: 2.422182083129883\n",
      "Epoch [27/50], Batch [44/56], Loss: 1.767932653427124\n",
      "Epoch [27/50], Batch [46/56], Loss: 1.8910293579101562\n",
      "Epoch [27/50], Batch [48/56], Loss: 1.8624277114868164\n",
      "Epoch [27/50], Batch [50/56], Loss: 2.0277562141418457\n",
      "Epoch [27/50], Batch [52/56], Loss: 1.9973950386047363\n",
      "Epoch [27/50], Batch [54/56], Loss: 2.2241642475128174\n",
      "Epoch [27/50], Batch [56/56], Loss: 2.7832088470458984\n",
      "Epoch [27/50] completed, Loss: 2.7832088470458984\n",
      "Epoch [28/50], Batch [2/56], Loss: 2.0299770832061768\n",
      "Epoch [28/50], Batch [4/56], Loss: 2.0651285648345947\n",
      "Epoch [28/50], Batch [6/56], Loss: 1.8949393033981323\n",
      "Epoch [28/50], Batch [8/56], Loss: 2.59670352935791\n",
      "Epoch [28/50], Batch [10/56], Loss: 2.2560200691223145\n",
      "Epoch [28/50], Batch [12/56], Loss: 1.9130315780639648\n",
      "Epoch [28/50], Batch [14/56], Loss: 2.15407395362854\n",
      "Epoch [28/50], Batch [16/56], Loss: 2.256086826324463\n",
      "Epoch [28/50], Batch [18/56], Loss: 1.9203590154647827\n",
      "Epoch [28/50], Batch [20/56], Loss: 2.158883810043335\n",
      "Epoch [28/50], Batch [22/56], Loss: 1.9071192741394043\n",
      "Epoch [28/50], Batch [24/56], Loss: 2.6416375637054443\n",
      "Epoch [28/50], Batch [26/56], Loss: 2.070533275604248\n",
      "Epoch [28/50], Batch [28/56], Loss: 2.2029576301574707\n",
      "Epoch [28/50], Batch [30/56], Loss: 1.9901018142700195\n",
      "Epoch [28/50], Batch [32/56], Loss: 1.9105515480041504\n",
      "Epoch [28/50], Batch [34/56], Loss: 2.276555061340332\n",
      "Epoch [28/50], Batch [36/56], Loss: 2.0571961402893066\n",
      "Epoch [28/50], Batch [38/56], Loss: 2.0067853927612305\n",
      "Epoch [28/50], Batch [40/56], Loss: 2.158496379852295\n",
      "Epoch [28/50], Batch [42/56], Loss: 2.4224603176116943\n",
      "Epoch [28/50], Batch [44/56], Loss: 1.7572665214538574\n",
      "Epoch [28/50], Batch [46/56], Loss: 1.8873015642166138\n",
      "Epoch [28/50], Batch [48/56], Loss: 1.8548870086669922\n",
      "Epoch [28/50], Batch [50/56], Loss: 2.023888111114502\n",
      "Epoch [28/50], Batch [52/56], Loss: 1.994672417640686\n",
      "Epoch [28/50], Batch [54/56], Loss: 2.2181105613708496\n",
      "Epoch [28/50], Batch [56/56], Loss: 2.782492160797119\n",
      "Epoch [28/50] completed, Loss: 2.782492160797119\n",
      "Epoch [29/50], Batch [2/56], Loss: 2.0229439735412598\n",
      "Epoch [29/50], Batch [4/56], Loss: 2.056443691253662\n",
      "Epoch [29/50], Batch [6/56], Loss: 1.8877065181732178\n",
      "Epoch [29/50], Batch [8/56], Loss: 2.594982624053955\n",
      "Epoch [29/50], Batch [10/56], Loss: 2.256253480911255\n",
      "Epoch [29/50], Batch [12/56], Loss: 1.9033896923065186\n",
      "Epoch [29/50], Batch [14/56], Loss: 2.154730796813965\n",
      "Epoch [29/50], Batch [16/56], Loss: 2.2563235759735107\n",
      "Epoch [29/50], Batch [18/56], Loss: 1.9124023914337158\n",
      "Epoch [29/50], Batch [20/56], Loss: 2.156006336212158\n",
      "Epoch [29/50], Batch [22/56], Loss: 1.9010233879089355\n",
      "Epoch [29/50], Batch [24/56], Loss: 2.646121025085449\n",
      "Epoch [29/50], Batch [26/56], Loss: 2.063544988632202\n",
      "Epoch [29/50], Batch [28/56], Loss: 2.1993439197540283\n",
      "Epoch [29/50], Batch [30/56], Loss: 1.9860095977783203\n",
      "Epoch [29/50], Batch [32/56], Loss: 1.900930404663086\n",
      "Epoch [29/50], Batch [34/56], Loss: 2.2726659774780273\n",
      "Epoch [29/50], Batch [36/56], Loss: 2.052070379257202\n",
      "Epoch [29/50], Batch [38/56], Loss: 2.0053725242614746\n",
      "Epoch [29/50], Batch [40/56], Loss: 2.1529529094696045\n",
      "Epoch [29/50], Batch [42/56], Loss: 2.422811985015869\n",
      "Epoch [29/50], Batch [44/56], Loss: 1.7467172145843506\n",
      "Epoch [29/50], Batch [46/56], Loss: 1.8836549520492554\n",
      "Epoch [29/50], Batch [48/56], Loss: 1.847463607788086\n",
      "Epoch [29/50], Batch [50/56], Loss: 2.020073652267456\n",
      "Epoch [29/50], Batch [52/56], Loss: 1.9920439720153809\n",
      "Epoch [29/50], Batch [54/56], Loss: 2.212106943130493\n",
      "Epoch [29/50], Batch [56/56], Loss: 2.7817931175231934\n",
      "Epoch [29/50] completed, Loss: 2.7817931175231934\n",
      "Epoch [30/50], Batch [2/56], Loss: 2.01601243019104\n",
      "Epoch [30/50], Batch [4/56], Loss: 2.047811508178711\n",
      "Epoch [30/50], Batch [6/56], Loss: 1.880558729171753\n",
      "Epoch [30/50], Batch [8/56], Loss: 2.5932650566101074\n",
      "Epoch [30/50], Batch [10/56], Loss: 2.256523609161377\n",
      "Epoch [30/50], Batch [12/56], Loss: 1.8938323259353638\n",
      "Epoch [30/50], Batch [14/56], Loss: 2.15541934967041\n",
      "Epoch [30/50], Batch [16/56], Loss: 2.2565970420837402\n",
      "Epoch [30/50], Batch [18/56], Loss: 1.9045597314834595\n",
      "Epoch [30/50], Batch [20/56], Loss: 2.1531643867492676\n",
      "Epoch [30/50], Batch [22/56], Loss: 1.8950072526931763\n",
      "Epoch [30/50], Batch [24/56], Loss: 2.6505987644195557\n",
      "Epoch [30/50], Batch [26/56], Loss: 2.056638240814209\n",
      "Epoch [30/50], Batch [28/56], Loss: 2.1957814693450928\n",
      "Epoch [30/50], Batch [30/56], Loss: 1.982002854347229\n",
      "Epoch [30/50], Batch [32/56], Loss: 1.8913928270339966\n",
      "Epoch [30/50], Batch [34/56], Loss: 2.268861770629883\n",
      "Epoch [30/50], Batch [36/56], Loss: 2.046992301940918\n",
      "Epoch [30/50], Batch [38/56], Loss: 2.004014492034912\n",
      "Epoch [30/50], Batch [40/56], Loss: 2.1474623680114746\n",
      "Epoch [30/50], Batch [42/56], Loss: 2.423236131668091\n",
      "Epoch [30/50], Batch [44/56], Loss: 1.736283540725708\n",
      "Epoch [30/50], Batch [46/56], Loss: 1.8800888061523438\n",
      "Epoch [30/50], Batch [48/56], Loss: 1.8401564359664917\n",
      "Epoch [30/50], Batch [50/56], Loss: 2.016312837600708\n",
      "Epoch [30/50], Batch [52/56], Loss: 1.989509105682373\n",
      "Epoch [30/50], Batch [54/56], Loss: 2.20615291595459\n",
      "Epoch [30/50], Batch [56/56], Loss: 2.7811105251312256\n",
      "Epoch [30/50] completed, Loss: 2.7811105251312256\n",
      "Epoch [31/50], Batch [2/56], Loss: 2.009181022644043\n",
      "Epoch [31/50], Batch [4/56], Loss: 2.0392308235168457\n",
      "Epoch [31/50], Batch [6/56], Loss: 1.8734949827194214\n",
      "Epoch [31/50], Batch [8/56], Loss: 2.591550350189209\n",
      "Epoch [31/50], Batch [10/56], Loss: 2.2568297386169434\n",
      "Epoch [31/50], Batch [12/56], Loss: 1.8843579292297363\n",
      "Epoch [31/50], Batch [14/56], Loss: 2.1561386585235596\n",
      "Epoch [31/50], Batch [16/56], Loss: 2.256906270980835\n",
      "Epoch [31/50], Batch [18/56], Loss: 1.896829605102539\n",
      "Epoch [31/50], Batch [20/56], Loss: 2.150358200073242\n",
      "Epoch [31/50], Batch [22/56], Loss: 1.8890703916549683\n",
      "Epoch [31/50], Batch [24/56], Loss: 2.6550700664520264\n",
      "Epoch [31/50], Batch [26/56], Loss: 2.0498125553131104\n",
      "Epoch [31/50], Batch [28/56], Loss: 2.1922686100006104\n",
      "Epoch [31/50], Batch [30/56], Loss: 1.9780807495117188\n",
      "Epoch [31/50], Batch [32/56], Loss: 1.881939172744751\n",
      "Epoch [31/50], Batch [34/56], Loss: 2.265141487121582\n",
      "Epoch [31/50], Batch [36/56], Loss: 2.041961669921875\n",
      "Epoch [31/50], Batch [38/56], Loss: 2.0027098655700684\n",
      "Epoch [31/50], Batch [40/56], Loss: 2.142024517059326\n",
      "Epoch [31/50], Batch [42/56], Loss: 2.4237310886383057\n",
      "Epoch [31/50], Batch [44/56], Loss: 1.7259645462036133\n",
      "Epoch [31/50], Batch [46/56], Loss: 1.8766026496887207\n",
      "Epoch [31/50], Batch [48/56], Loss: 1.8329644203186035\n",
      "Epoch [31/50], Batch [50/56], Loss: 2.0126051902770996\n",
      "Epoch [31/50], Batch [52/56], Loss: 1.9870669841766357\n",
      "Epoch [31/50], Batch [54/56], Loss: 2.2002482414245605\n",
      "Epoch [31/50], Batch [56/56], Loss: 2.780444860458374\n",
      "Epoch [31/50] completed, Loss: 2.780444860458374\n",
      "Epoch [32/50], Batch [2/56], Loss: 2.0024490356445312\n",
      "Epoch [32/50], Batch [4/56], Loss: 2.0307023525238037\n",
      "Epoch [32/50], Batch [6/56], Loss: 1.8665155172348022\n",
      "Epoch [32/50], Batch [8/56], Loss: 2.5898385047912598\n",
      "Epoch [32/50], Batch [10/56], Loss: 2.257171154022217\n",
      "Epoch [32/50], Batch [12/56], Loss: 1.874967098236084\n",
      "Epoch [32/50], Batch [14/56], Loss: 2.156888961791992\n",
      "Epoch [32/50], Batch [16/56], Loss: 2.2572505474090576\n",
      "Epoch [32/50], Batch [18/56], Loss: 1.8892104625701904\n",
      "Epoch [32/50], Batch [20/56], Loss: 2.1475868225097656\n",
      "Epoch [32/50], Batch [22/56], Loss: 1.8832125663757324\n",
      "Epoch [32/50], Batch [24/56], Loss: 2.659534454345703\n",
      "Epoch [32/50], Batch [26/56], Loss: 2.04306697845459\n",
      "Epoch [32/50], Batch [28/56], Loss: 2.1888058185577393\n",
      "Epoch [32/50], Batch [30/56], Loss: 1.9742424488067627\n",
      "Epoch [32/50], Batch [32/56], Loss: 1.8725686073303223\n",
      "Epoch [32/50], Batch [34/56], Loss: 2.261503219604492\n",
      "Epoch [32/50], Batch [36/56], Loss: 2.0369794368743896\n",
      "Epoch [32/50], Batch [38/56], Loss: 2.0014584064483643\n",
      "Epoch [32/50], Batch [40/56], Loss: 2.136638641357422\n",
      "Epoch [32/50], Batch [42/56], Loss: 2.4242963790893555\n",
      "Epoch [32/50], Batch [44/56], Loss: 1.7157593965530396\n",
      "Epoch [32/50], Batch [46/56], Loss: 1.8731954097747803\n",
      "Epoch [32/50], Batch [48/56], Loss: 1.8258862495422363\n",
      "Epoch [32/50], Batch [50/56], Loss: 2.00895094871521\n",
      "Epoch [32/50], Batch [52/56], Loss: 1.984716773033142\n",
      "Epoch [32/50], Batch [54/56], Loss: 2.194392204284668\n",
      "Epoch [32/50], Batch [56/56], Loss: 2.779794692993164\n",
      "Epoch [32/50] completed, Loss: 2.779794692993164\n",
      "Epoch [33/50], Batch [2/56], Loss: 1.9958159923553467\n",
      "Epoch [33/50], Batch [4/56], Loss: 2.022226333618164\n",
      "Epoch [33/50], Batch [6/56], Loss: 1.859618902206421\n",
      "Epoch [33/50], Batch [8/56], Loss: 2.5881295204162598\n",
      "Epoch [33/50], Batch [10/56], Loss: 2.257546901702881\n",
      "Epoch [33/50], Batch [12/56], Loss: 1.8656589984893799\n",
      "Epoch [33/50], Batch [14/56], Loss: 2.15766978263855\n",
      "Epoch [33/50], Batch [16/56], Loss: 2.257629632949829\n",
      "Epoch [33/50], Batch [18/56], Loss: 1.881701111793518\n",
      "Epoch [33/50], Batch [20/56], Loss: 2.144850254058838\n",
      "Epoch [33/50], Batch [22/56], Loss: 1.877433180809021\n",
      "Epoch [33/50], Batch [24/56], Loss: 2.6639914512634277\n",
      "Epoch [33/50], Batch [26/56], Loss: 2.036400318145752\n",
      "Epoch [33/50], Batch [28/56], Loss: 2.185391426086426\n",
      "Epoch [33/50], Batch [30/56], Loss: 1.9704866409301758\n",
      "Epoch [33/50], Batch [32/56], Loss: 1.8632805347442627\n",
      "Epoch [33/50], Batch [34/56], Loss: 2.257946491241455\n",
      "Epoch [33/50], Batch [36/56], Loss: 2.032045364379883\n",
      "Epoch [33/50], Batch [38/56], Loss: 2.000260353088379\n",
      "Epoch [33/50], Batch [40/56], Loss: 2.1313047409057617\n",
      "Epoch [33/50], Batch [42/56], Loss: 2.4249298572540283\n",
      "Epoch [33/50], Batch [44/56], Loss: 1.70566725730896\n",
      "Epoch [33/50], Batch [46/56], Loss: 1.8698663711547852\n",
      "Epoch [33/50], Batch [48/56], Loss: 1.8189200162887573\n",
      "Epoch [33/50], Batch [50/56], Loss: 2.0053486824035645\n",
      "Epoch [33/50], Batch [52/56], Loss: 1.9824578762054443\n",
      "Epoch [33/50], Batch [54/56], Loss: 2.188584566116333\n",
      "Epoch [33/50], Batch [56/56], Loss: 2.7791595458984375\n",
      "Epoch [33/50] completed, Loss: 2.7791595458984375\n",
      "Epoch [34/50], Batch [2/56], Loss: 1.989280343055725\n",
      "Epoch [34/50], Batch [4/56], Loss: 2.0138027667999268\n",
      "Epoch [34/50], Batch [6/56], Loss: 1.8528048992156982\n",
      "Epoch [34/50], Batch [8/56], Loss: 2.586423873901367\n",
      "Epoch [34/50], Batch [10/56], Loss: 2.2579565048217773\n",
      "Epoch [34/50], Batch [12/56], Loss: 1.856433391571045\n",
      "Epoch [34/50], Batch [14/56], Loss: 2.158480644226074\n",
      "Epoch [34/50], Batch [16/56], Loss: 2.258042335510254\n",
      "Epoch [34/50], Batch [18/56], Loss: 1.8743001222610474\n",
      "Epoch [34/50], Batch [20/56], Loss: 2.142148017883301\n",
      "Epoch [34/50], Batch [22/56], Loss: 1.8717318773269653\n",
      "Epoch [34/50], Batch [24/56], Loss: 2.668440341949463\n",
      "Epoch [34/50], Batch [26/56], Loss: 2.0298120975494385\n",
      "Epoch [34/50], Batch [28/56], Loss: 2.18202543258667\n",
      "Epoch [34/50], Batch [30/56], Loss: 1.966812252998352\n",
      "Epoch [34/50], Batch [32/56], Loss: 1.8540751934051514\n",
      "Epoch [34/50], Batch [34/56], Loss: 2.254469871520996\n",
      "Epoch [34/50], Batch [36/56], Loss: 2.0271592140197754\n",
      "Epoch [34/50], Batch [38/56], Loss: 1.9991137981414795\n",
      "Epoch [34/50], Batch [40/56], Loss: 2.1260225772857666\n",
      "Epoch [34/50], Batch [42/56], Loss: 2.425631284713745\n",
      "Epoch [34/50], Batch [44/56], Loss: 1.6956870555877686\n",
      "Epoch [34/50], Batch [46/56], Loss: 1.8666152954101562\n",
      "Epoch [34/50], Batch [48/56], Loss: 1.8120652437210083\n",
      "Epoch [34/50], Batch [50/56], Loss: 2.001798391342163\n",
      "Epoch [34/50], Batch [52/56], Loss: 1.980289340019226\n",
      "Epoch [34/50], Batch [54/56], Loss: 2.1828248500823975\n",
      "Epoch [34/50], Batch [56/56], Loss: 2.7785394191741943\n",
      "Epoch [34/50] completed, Loss: 2.7785394191741943\n",
      "Epoch [35/50], Batch [2/56], Loss: 1.982841968536377\n",
      "Epoch [35/50], Batch [4/56], Loss: 2.0054314136505127\n",
      "Epoch [35/50], Batch [6/56], Loss: 1.8460724353790283\n",
      "Epoch [35/50], Batch [8/56], Loss: 2.584721088409424\n",
      "Epoch [35/50], Batch [10/56], Loss: 2.258399248123169\n",
      "Epoch [35/50], Batch [12/56], Loss: 1.8472900390625\n",
      "Epoch [35/50], Batch [14/56], Loss: 2.1593210697174072\n",
      "Epoch [35/50], Batch [16/56], Loss: 2.2584877014160156\n",
      "Epoch [35/50], Batch [18/56], Loss: 1.8670060634613037\n",
      "Epoch [35/50], Batch [20/56], Loss: 2.139479637145996\n",
      "Epoch [35/50], Batch [22/56], Loss: 1.8661081790924072\n",
      "Epoch [35/50], Batch [24/56], Loss: 2.6728806495666504\n",
      "Epoch [35/50], Batch [26/56], Loss: 2.023301124572754\n",
      "Epoch [35/50], Batch [28/56], Loss: 2.178706645965576\n",
      "Epoch [35/50], Batch [30/56], Loss: 1.963218331336975\n",
      "Epoch [35/50], Batch [32/56], Loss: 1.8449513912200928\n",
      "Epoch [35/50], Batch [34/56], Loss: 2.2510719299316406\n",
      "Epoch [35/50], Batch [36/56], Loss: 2.0223209857940674\n",
      "Epoch [35/50], Batch [38/56], Loss: 1.998018503189087\n",
      "Epoch [35/50], Batch [40/56], Loss: 2.1207919120788574\n",
      "Epoch [35/50], Batch [42/56], Loss: 2.4263994693756104\n",
      "Epoch [35/50], Batch [44/56], Loss: 1.6858179569244385\n",
      "Epoch [35/50], Batch [46/56], Loss: 1.8634414672851562\n",
      "Epoch [35/50], Batch [48/56], Loss: 1.8053206205368042\n",
      "Epoch [35/50], Batch [50/56], Loss: 1.9982998371124268\n",
      "Epoch [35/50], Batch [52/56], Loss: 1.9782108068466187\n",
      "Epoch [35/50], Batch [54/56], Loss: 2.1771130561828613\n",
      "Epoch [35/50], Batch [56/56], Loss: 2.7779338359832764\n",
      "Epoch [35/50] completed, Loss: 2.7779338359832764\n",
      "Epoch [36/50], Batch [2/56], Loss: 1.9764995574951172\n",
      "Epoch [36/50], Batch [4/56], Loss: 1.997112512588501\n",
      "Epoch [36/50], Batch [6/56], Loss: 1.839421272277832\n",
      "Epoch [36/50], Batch [8/56], Loss: 2.583021640777588\n",
      "Epoch [36/50], Batch [10/56], Loss: 2.2588741779327393\n",
      "Epoch [36/50], Batch [12/56], Loss: 1.8382278680801392\n",
      "Epoch [36/50], Batch [14/56], Loss: 2.1601908206939697\n",
      "Epoch [36/50], Batch [16/56], Loss: 2.258965492248535\n",
      "Epoch [36/50], Batch [18/56], Loss: 1.8598179817199707\n",
      "Epoch [36/50], Batch [20/56], Loss: 2.1368448734283447\n",
      "Epoch [36/50], Batch [22/56], Loss: 1.8605618476867676\n",
      "Epoch [36/50], Batch [24/56], Loss: 2.677311897277832\n",
      "Epoch [36/50], Batch [26/56], Loss: 2.016866683959961\n",
      "Epoch [36/50], Batch [28/56], Loss: 2.1754348278045654\n",
      "Epoch [36/50], Batch [30/56], Loss: 1.959704041481018\n",
      "Epoch [36/50], Batch [32/56], Loss: 1.835909366607666\n",
      "Epoch [36/50], Batch [34/56], Loss: 2.2477526664733887\n",
      "Epoch [36/50], Batch [36/56], Loss: 2.017531394958496\n",
      "Epoch [36/50], Batch [38/56], Loss: 1.9969735145568848\n",
      "Epoch [36/50], Batch [40/56], Loss: 2.115612030029297\n",
      "Epoch [36/50], Batch [42/56], Loss: 2.427232503890991\n",
      "Epoch [36/50], Batch [44/56], Loss: 1.6760594844818115\n",
      "Epoch [36/50], Batch [46/56], Loss: 1.8603439331054688\n",
      "Epoch [36/50], Batch [48/56], Loss: 1.7986845970153809\n",
      "Epoch [36/50], Batch [50/56], Loss: 1.994852066040039\n",
      "Epoch [36/50], Batch [52/56], Loss: 1.9762213230133057\n",
      "Epoch [36/50], Batch [54/56], Loss: 2.171448230743408\n",
      "Epoch [36/50], Batch [56/56], Loss: 2.777341365814209\n",
      "Epoch [36/50] completed, Loss: 2.777341365814209\n",
      "Epoch [37/50], Batch [2/56], Loss: 1.9702520370483398\n",
      "Epoch [37/50], Batch [4/56], Loss: 1.9888461828231812\n",
      "Epoch [37/50], Batch [6/56], Loss: 1.832850456237793\n",
      "Epoch [37/50], Batch [8/56], Loss: 2.581324815750122\n",
      "Epoch [37/50], Batch [10/56], Loss: 2.25938081741333\n",
      "Epoch [37/50], Batch [12/56], Loss: 1.829247236251831\n",
      "Epoch [37/50], Batch [14/56], Loss: 2.1610898971557617\n",
      "Epoch [37/50], Batch [16/56], Loss: 2.259474992752075\n",
      "Epoch [37/50], Batch [18/56], Loss: 1.8527343273162842\n",
      "Epoch [37/50], Batch [20/56], Loss: 2.1342434883117676\n",
      "Epoch [37/50], Batch [22/56], Loss: 1.8550925254821777\n",
      "Epoch [37/50], Batch [24/56], Loss: 2.6817331314086914\n",
      "Epoch [37/50], Batch [26/56], Loss: 2.0105080604553223\n",
      "Epoch [37/50], Batch [28/56], Loss: 2.1722095012664795\n",
      "Epoch [37/50], Batch [30/56], Loss: 1.9562684297561646\n",
      "Epoch [37/50], Batch [32/56], Loss: 1.8269484043121338\n",
      "Epoch [37/50], Batch [34/56], Loss: 2.2445099353790283\n",
      "Epoch [37/50], Batch [36/56], Loss: 2.012789726257324\n",
      "Epoch [37/50], Batch [38/56], Loss: 1.995978832244873\n",
      "Epoch [37/50], Batch [40/56], Loss: 2.110483169555664\n",
      "Epoch [37/50], Batch [42/56], Loss: 2.4281303882598877\n",
      "Epoch [37/50], Batch [44/56], Loss: 1.6664103269577026\n",
      "Epoch [37/50], Batch [46/56], Loss: 1.8573222160339355\n",
      "Epoch [37/50], Batch [48/56], Loss: 1.7921565771102905\n",
      "Epoch [37/50], Batch [50/56], Loss: 1.991455078125\n",
      "Epoch [37/50], Batch [52/56], Loss: 1.9743201732635498\n",
      "Epoch [37/50], Batch [54/56], Loss: 2.165830612182617\n",
      "Epoch [37/50], Batch [56/56], Loss: 2.776761770248413\n",
      "Epoch [37/50] completed, Loss: 2.776761770248413\n",
      "Epoch [38/50], Batch [2/56], Loss: 1.9640991687774658\n",
      "Epoch [38/50], Batch [4/56], Loss: 1.9806323051452637\n",
      "Epoch [38/50], Batch [6/56], Loss: 1.826359510421753\n",
      "Epoch [38/50], Batch [8/56], Loss: 2.5796308517456055\n",
      "Epoch [38/50], Batch [10/56], Loss: 2.259918212890625\n",
      "Epoch [38/50], Batch [12/56], Loss: 1.8203473091125488\n",
      "Epoch [38/50], Batch [14/56], Loss: 2.1620171070098877\n",
      "Epoch [38/50], Batch [16/56], Loss: 2.2600154876708984\n",
      "Epoch [38/50], Batch [18/56], Loss: 1.8457540273666382\n",
      "Epoch [38/50], Batch [20/56], Loss: 2.131674289703369\n",
      "Epoch [38/50], Batch [22/56], Loss: 1.84969961643219\n",
      "Epoch [38/50], Batch [24/56], Loss: 2.6861438751220703\n",
      "Epoch [38/50], Batch [26/56], Loss: 2.0042243003845215\n",
      "Epoch [38/50], Batch [28/56], Loss: 2.1690292358398438\n",
      "Epoch [38/50], Batch [30/56], Loss: 1.952910304069519\n",
      "Epoch [38/50], Batch [32/56], Loss: 1.8180679082870483\n",
      "Epoch [38/50], Batch [34/56], Loss: 2.2413434982299805\n",
      "Epoch [38/50], Batch [36/56], Loss: 2.00809645652771\n",
      "Epoch [38/50], Batch [38/56], Loss: 1.995032787322998\n",
      "Epoch [38/50], Batch [40/56], Loss: 2.1054046154022217\n",
      "Epoch [38/50], Batch [42/56], Loss: 2.429090976715088\n",
      "Epoch [38/50], Batch [44/56], Loss: 1.6568701267242432\n",
      "Epoch [38/50], Batch [46/56], Loss: 1.8543756008148193\n",
      "Epoch [38/50], Batch [48/56], Loss: 1.7857348918914795\n",
      "Epoch [38/50], Batch [50/56], Loss: 1.9881078004837036\n",
      "Epoch [38/50], Batch [52/56], Loss: 1.9725068807601929\n",
      "Epoch [38/50], Batch [54/56], Loss: 2.1602587699890137\n",
      "Epoch [38/50], Batch [56/56], Loss: 2.7761950492858887\n",
      "Epoch [38/50] completed, Loss: 2.7761950492858887\n",
      "Epoch [39/50], Batch [2/56], Loss: 1.95803964138031\n",
      "Epoch [39/50], Batch [4/56], Loss: 1.972470760345459\n",
      "Epoch [39/50], Batch [6/56], Loss: 1.819947600364685\n",
      "Epoch [39/50], Batch [8/56], Loss: 2.577939987182617\n",
      "Epoch [39/50], Batch [10/56], Loss: 2.260486125946045\n",
      "Epoch [39/50], Batch [12/56], Loss: 1.8115277290344238\n",
      "Epoch [39/50], Batch [14/56], Loss: 2.1629724502563477\n",
      "Epoch [39/50], Batch [16/56], Loss: 2.2605857849121094\n",
      "Epoch [39/50], Batch [18/56], Loss: 1.838875651359558\n",
      "Epoch [39/50], Batch [20/56], Loss: 2.129138231277466\n",
      "Epoch [39/50], Batch [22/56], Loss: 1.844382643699646\n",
      "Epoch [39/50], Batch [24/56], Loss: 2.6905434131622314\n",
      "Epoch [39/50], Batch [26/56], Loss: 1.9980146884918213\n",
      "Epoch [39/50], Batch [28/56], Loss: 2.165893793106079\n",
      "Epoch [39/50], Batch [30/56], Loss: 1.9496290683746338\n",
      "Epoch [39/50], Batch [32/56], Loss: 1.8092679977416992\n",
      "Epoch [39/50], Batch [34/56], Loss: 2.2382519245147705\n",
      "Epoch [39/50], Batch [36/56], Loss: 2.003451347351074\n",
      "Epoch [39/50], Batch [38/56], Loss: 1.9941349029541016\n",
      "Epoch [39/50], Batch [40/56], Loss: 2.1003761291503906\n",
      "Epoch [39/50], Batch [42/56], Loss: 2.430114269256592\n",
      "Epoch [39/50], Batch [44/56], Loss: 1.6474378108978271\n",
      "Epoch [39/50], Batch [46/56], Loss: 1.8515034914016724\n",
      "Epoch [39/50], Batch [48/56], Loss: 1.7794190645217896\n",
      "Epoch [39/50], Batch [50/56], Loss: 1.9848101139068604\n",
      "Epoch [39/50], Batch [52/56], Loss: 1.970780372619629\n",
      "Epoch [39/50], Batch [54/56], Loss: 2.1547329425811768\n",
      "Epoch [39/50], Batch [56/56], Loss: 2.7756400108337402\n",
      "Epoch [39/50] completed, Loss: 2.7756400108337402\n",
      "Epoch [40/50], Batch [2/56], Loss: 1.9520728588104248\n",
      "Epoch [40/50], Batch [4/56], Loss: 1.9643619060516357\n",
      "Epoch [40/50], Batch [6/56], Loss: 1.8136141300201416\n",
      "Epoch [40/50], Batch [8/56], Loss: 2.576251983642578\n",
      "Epoch [40/50], Batch [10/56], Loss: 2.2610836029052734\n",
      "Epoch [40/50], Batch [12/56], Loss: 1.8027880191802979\n",
      "Epoch [40/50], Batch [14/56], Loss: 2.1639556884765625\n",
      "Epoch [40/50], Batch [16/56], Loss: 2.261186122894287\n",
      "Epoch [40/50], Batch [18/56], Loss: 1.8320982456207275\n",
      "Epoch [40/50], Batch [20/56], Loss: 2.126633644104004\n",
      "Epoch [40/50], Batch [22/56], Loss: 1.8391413688659668\n",
      "Epoch [40/50], Batch [24/56], Loss: 2.694931745529175\n",
      "Epoch [40/50], Batch [26/56], Loss: 1.9918782711029053\n",
      "Epoch [40/50], Batch [28/56], Loss: 2.1628029346466064\n",
      "Epoch [40/50], Batch [30/56], Loss: 1.9464235305786133\n",
      "Epoch [40/50], Batch [32/56], Loss: 1.8005478382110596\n",
      "Epoch [40/50], Batch [34/56], Loss: 2.235234498977661\n",
      "Epoch [40/50], Batch [36/56], Loss: 1.9988540410995483\n",
      "Epoch [40/50], Batch [38/56], Loss: 1.9932844638824463\n",
      "Epoch [40/50], Batch [40/56], Loss: 2.095397710800171\n",
      "Epoch [40/50], Batch [42/56], Loss: 2.4311985969543457\n",
      "Epoch [40/50], Batch [44/56], Loss: 1.6381124258041382\n",
      "Epoch [40/50], Batch [46/56], Loss: 1.8487049341201782\n",
      "Epoch [40/50], Batch [48/56], Loss: 1.7732073068618774\n",
      "Epoch [40/50], Batch [50/56], Loss: 1.981561541557312\n",
      "Epoch [40/50], Batch [52/56], Loss: 1.9691402912139893\n",
      "Epoch [40/50], Batch [54/56], Loss: 2.1492528915405273\n",
      "Epoch [40/50], Batch [56/56], Loss: 2.7750964164733887\n",
      "Epoch [40/50] completed, Loss: 2.7750964164733887\n",
      "Epoch [41/50], Batch [2/56], Loss: 1.9461982250213623\n",
      "Epoch [41/50], Batch [4/56], Loss: 1.9563052654266357\n",
      "Epoch [41/50], Batch [6/56], Loss: 1.807358741760254\n",
      "Epoch [41/50], Batch [8/56], Loss: 2.5745668411254883\n",
      "Epoch [41/50], Batch [10/56], Loss: 2.261709690093994\n",
      "Epoch [41/50], Batch [12/56], Loss: 1.7941282987594604\n",
      "Epoch [41/50], Batch [14/56], Loss: 2.164966106414795\n",
      "Epoch [41/50], Batch [16/56], Loss: 2.261815071105957\n",
      "Epoch [41/50], Batch [18/56], Loss: 1.8254204988479614\n",
      "Epoch [41/50], Batch [20/56], Loss: 2.1241610050201416\n",
      "Epoch [41/50], Batch [22/56], Loss: 1.833975076675415\n",
      "Epoch [41/50], Batch [24/56], Loss: 2.699307441711426\n",
      "Epoch [41/50], Batch [26/56], Loss: 1.9858143329620361\n",
      "Epoch [41/50], Batch [28/56], Loss: 2.159754991531372\n",
      "Epoch [41/50], Batch [30/56], Loss: 1.9432928562164307\n",
      "Epoch [41/50], Batch [32/56], Loss: 1.7919074296951294\n",
      "Epoch [41/50], Batch [34/56], Loss: 2.232290267944336\n",
      "Epoch [41/50], Batch [36/56], Loss: 1.994304895401001\n",
      "Epoch [41/50], Batch [38/56], Loss: 1.9924811124801636\n",
      "Epoch [41/50], Batch [40/56], Loss: 2.0904688835144043\n",
      "Epoch [41/50], Batch [42/56], Loss: 2.432342529296875\n",
      "Epoch [41/50], Batch [44/56], Loss: 1.6288938522338867\n",
      "Epoch [41/50], Batch [46/56], Loss: 1.8459794521331787\n",
      "Epoch [41/50], Batch [48/56], Loss: 1.767099380493164\n",
      "Epoch [41/50], Batch [50/56], Loss: 1.9783614873886108\n",
      "Epoch [41/50], Batch [52/56], Loss: 1.967585563659668\n",
      "Epoch [41/50], Batch [54/56], Loss: 2.143817663192749\n",
      "Epoch [41/50], Batch [56/56], Loss: 2.7745635509490967\n",
      "Epoch [41/50] completed, Loss: 2.7745635509490967\n",
      "Epoch [42/50], Batch [2/56], Loss: 1.9404144287109375\n",
      "Epoch [42/50], Batch [4/56], Loss: 1.9483013153076172\n",
      "Epoch [42/50], Batch [6/56], Loss: 1.8011806011199951\n",
      "Epoch [42/50], Batch [8/56], Loss: 2.5728845596313477\n",
      "Epoch [42/50], Batch [10/56], Loss: 2.262364625930786\n",
      "Epoch [42/50], Batch [12/56], Loss: 1.7855476140975952\n",
      "Epoch [42/50], Batch [14/56], Loss: 2.1660032272338867\n",
      "Epoch [42/50], Batch [16/56], Loss: 2.26247239112854\n",
      "Epoch [42/50], Batch [18/56], Loss: 1.8188412189483643\n",
      "Epoch [42/50], Batch [20/56], Loss: 2.1217198371887207\n",
      "Epoch [42/50], Batch [22/56], Loss: 1.8288835287094116\n",
      "Epoch [42/50], Batch [24/56], Loss: 2.7036705017089844\n",
      "Epoch [42/50], Batch [26/56], Loss: 1.979821801185608\n",
      "Epoch [42/50], Batch [28/56], Loss: 2.156750202178955\n",
      "Epoch [42/50], Batch [30/56], Loss: 1.9402360916137695\n",
      "Epoch [42/50], Batch [32/56], Loss: 1.7833459377288818\n",
      "Epoch [42/50], Batch [34/56], Loss: 2.2294178009033203\n",
      "Epoch [42/50], Batch [36/56], Loss: 1.9898037910461426\n",
      "Epoch [42/50], Batch [38/56], Loss: 1.9917237758636475\n",
      "Epoch [42/50], Batch [40/56], Loss: 2.0855891704559326\n",
      "Epoch [42/50], Batch [42/56], Loss: 2.4335455894470215\n",
      "Epoch [42/50], Batch [44/56], Loss: 1.6197806596755981\n",
      "Epoch [42/50], Batch [46/56], Loss: 1.8433265686035156\n",
      "Epoch [42/50], Batch [48/56], Loss: 1.7610933780670166\n",
      "Epoch [42/50], Batch [50/56], Loss: 1.9752095937728882\n",
      "Epoch [42/50], Batch [52/56], Loss: 1.966115951538086\n",
      "Epoch [42/50], Batch [54/56], Loss: 2.138427257537842\n",
      "Epoch [42/50], Batch [56/56], Loss: 2.774040937423706\n",
      "Epoch [42/50] completed, Loss: 2.774040937423706\n",
      "Epoch [43/50], Batch [2/56], Loss: 1.9347209930419922\n",
      "Epoch [43/50], Batch [4/56], Loss: 1.940349817276001\n",
      "Epoch [43/50], Batch [6/56], Loss: 1.795078992843628\n",
      "Epoch [43/50], Batch [8/56], Loss: 2.5712053775787354\n",
      "Epoch [43/50], Batch [10/56], Loss: 2.2630467414855957\n",
      "Epoch [43/50], Batch [12/56], Loss: 1.7770459651947021\n",
      "Epoch [43/50], Batch [14/56], Loss: 2.167067050933838\n",
      "Epoch [43/50], Batch [16/56], Loss: 2.263157367706299\n",
      "Epoch [43/50], Batch [18/56], Loss: 1.812359094619751\n",
      "Epoch [43/50], Batch [20/56], Loss: 2.119309425354004\n",
      "Epoch [43/50], Batch [22/56], Loss: 1.8238661289215088\n",
      "Epoch [43/50], Batch [24/56], Loss: 2.708019971847534\n",
      "Epoch [43/50], Batch [26/56], Loss: 1.973900318145752\n",
      "Epoch [43/50], Batch [28/56], Loss: 2.15378737449646\n",
      "Epoch [43/50], Batch [30/56], Loss: 1.9372522830963135\n",
      "Epoch [43/50], Batch [32/56], Loss: 1.7748632431030273\n",
      "Epoch [43/50], Batch [34/56], Loss: 2.226616859436035\n",
      "Epoch [43/50], Batch [36/56], Loss: 1.9853503704071045\n",
      "Epoch [43/50], Batch [38/56], Loss: 1.9910115003585815\n",
      "Epoch [43/50], Batch [40/56], Loss: 2.0807583332061768\n",
      "Epoch [43/50], Batch [42/56], Loss: 2.4348063468933105\n",
      "Epoch [43/50], Batch [44/56], Loss: 1.6107723712921143\n",
      "Epoch [43/50], Batch [46/56], Loss: 1.8407450914382935\n",
      "Epoch [43/50], Batch [48/56], Loss: 1.7551887035369873\n",
      "Epoch [43/50], Batch [50/56], Loss: 1.9721050262451172\n",
      "Epoch [43/50], Batch [52/56], Loss: 1.9647302627563477\n",
      "Epoch [43/50], Batch [54/56], Loss: 2.1330809593200684\n",
      "Epoch [43/50], Batch [56/56], Loss: 2.7735280990600586\n",
      "Epoch [43/50] completed, Loss: 2.7735280990600586\n",
      "Epoch [44/50], Batch [2/56], Loss: 1.9291167259216309\n",
      "Epoch [44/50], Batch [4/56], Loss: 1.932450532913208\n",
      "Epoch [44/50], Batch [6/56], Loss: 1.789053201675415\n",
      "Epoch [44/50], Batch [8/56], Loss: 2.5695290565490723\n",
      "Epoch [44/50], Batch [10/56], Loss: 2.263756275177002\n",
      "Epoch [44/50], Batch [12/56], Loss: 1.7686223983764648\n",
      "Epoch [44/50], Batch [14/56], Loss: 2.168156623840332\n",
      "Epoch [44/50], Batch [16/56], Loss: 2.263869285583496\n",
      "Epoch [44/50], Batch [18/56], Loss: 1.805972933769226\n",
      "Epoch [44/50], Batch [20/56], Loss: 2.116929769515991\n",
      "Epoch [44/50], Batch [22/56], Loss: 1.8189226388931274\n",
      "Epoch [44/50], Batch [24/56], Loss: 2.712355136871338\n",
      "Epoch [44/50], Batch [26/56], Loss: 1.9680488109588623\n",
      "Epoch [44/50], Batch [28/56], Loss: 2.1508660316467285\n",
      "Epoch [44/50], Batch [30/56], Loss: 1.9343403577804565\n",
      "Epoch [44/50], Batch [32/56], Loss: 1.7664587497711182\n",
      "Epoch [44/50], Batch [34/56], Loss: 2.223886251449585\n",
      "Epoch [44/50], Batch [36/56], Loss: 1.9809448719024658\n",
      "Epoch [44/50], Batch [38/56], Loss: 1.9903438091278076\n",
      "Epoch [44/50], Batch [40/56], Loss: 2.0759763717651367\n",
      "Epoch [44/50], Batch [42/56], Loss: 2.436123847961426\n",
      "Epoch [44/50], Batch [44/56], Loss: 1.601867914199829\n",
      "Epoch [44/50], Batch [46/56], Loss: 1.838234543800354\n",
      "Epoch [44/50], Batch [48/56], Loss: 1.7493842840194702\n",
      "Epoch [44/50], Batch [50/56], Loss: 1.9690476655960083\n",
      "Epoch [44/50], Batch [52/56], Loss: 1.963428020477295\n",
      "Epoch [44/50], Batch [54/56], Loss: 2.1277782917022705\n",
      "Epoch [44/50], Batch [56/56], Loss: 2.7730250358581543\n",
      "Epoch [44/50] completed, Loss: 2.7730250358581543\n",
      "Epoch [45/50], Batch [2/56], Loss: 1.9236010313034058\n",
      "Epoch [45/50], Batch [4/56], Loss: 1.9246037006378174\n",
      "Epoch [45/50], Batch [6/56], Loss: 1.7831029891967773\n",
      "Epoch [45/50], Batch [8/56], Loss: 2.5678558349609375\n",
      "Epoch [45/50], Batch [10/56], Loss: 2.2644920349121094\n",
      "Epoch [45/50], Batch [12/56], Loss: 1.7602770328521729\n",
      "Epoch [45/50], Batch [14/56], Loss: 2.169271945953369\n",
      "Epoch [45/50], Batch [16/56], Loss: 2.2646071910858154\n",
      "Epoch [45/50], Batch [18/56], Loss: 1.7996816635131836\n",
      "Epoch [45/50], Batch [20/56], Loss: 2.1145801544189453\n",
      "Epoch [45/50], Batch [22/56], Loss: 1.8140525817871094\n",
      "Epoch [45/50], Batch [24/56], Loss: 2.7166757583618164\n",
      "Epoch [45/50], Batch [26/56], Loss: 1.962266206741333\n",
      "Epoch [45/50], Batch [28/56], Loss: 2.1479854583740234\n",
      "Epoch [45/50], Batch [30/56], Loss: 1.931499719619751\n",
      "Epoch [45/50], Batch [32/56], Loss: 1.7581324577331543\n",
      "Epoch [45/50], Batch [34/56], Loss: 2.221224784851074\n",
      "Epoch [45/50], Batch [36/56], Loss: 1.9765870571136475\n",
      "Epoch [45/50], Batch [38/56], Loss: 1.989720106124878\n",
      "Epoch [45/50], Batch [40/56], Loss: 2.0712428092956543\n",
      "Epoch [45/50], Batch [42/56], Loss: 2.4374969005584717\n",
      "Epoch [45/50], Batch [44/56], Loss: 1.593066930770874\n",
      "Epoch [45/50], Batch [46/56], Loss: 1.8357939720153809\n",
      "Epoch [45/50], Batch [48/56], Loss: 1.7436790466308594\n",
      "Epoch [45/50], Batch [50/56], Loss: 1.9660365581512451\n",
      "Epoch [45/50], Batch [52/56], Loss: 1.9622083902359009\n",
      "Epoch [45/50], Batch [54/56], Loss: 2.1225194931030273\n",
      "Epoch [45/50], Batch [56/56], Loss: 2.7725303173065186\n",
      "Epoch [45/50] completed, Loss: 2.7725303173065186\n",
      "Epoch [46/50], Batch [2/56], Loss: 1.91817307472229\n",
      "Epoch [46/50], Batch [4/56], Loss: 1.9168092012405396\n",
      "Epoch [46/50], Batch [6/56], Loss: 1.7772270441055298\n",
      "Epoch [46/50], Batch [8/56], Loss: 2.566185712814331\n",
      "Epoch [46/50], Batch [10/56], Loss: 2.2652533054351807\n",
      "Epoch [46/50], Batch [12/56], Loss: 1.752009391784668\n",
      "Epoch [46/50], Batch [14/56], Loss: 2.17041277885437\n",
      "Epoch [46/50], Batch [16/56], Loss: 2.265371322631836\n",
      "Epoch [46/50], Batch [18/56], Loss: 1.7934843301773071\n",
      "Epoch [46/50], Batch [20/56], Loss: 2.1122608184814453\n",
      "Epoch [46/50], Batch [22/56], Loss: 1.8092548847198486\n",
      "Epoch [46/50], Batch [24/56], Loss: 2.7209815979003906\n",
      "Epoch [46/50], Batch [26/56], Loss: 1.9565523862838745\n",
      "Epoch [46/50], Batch [28/56], Loss: 2.1451454162597656\n",
      "Epoch [46/50], Batch [30/56], Loss: 1.9287290573120117\n",
      "Epoch [46/50], Batch [32/56], Loss: 1.7498835325241089\n",
      "Epoch [46/50], Batch [34/56], Loss: 2.2186319828033447\n",
      "Epoch [46/50], Batch [36/56], Loss: 1.9722768068313599\n",
      "Epoch [46/50], Batch [38/56], Loss: 1.9891390800476074\n",
      "Epoch [46/50], Batch [40/56], Loss: 2.0665571689605713\n",
      "Epoch [46/50], Batch [42/56], Loss: 2.43892502784729\n",
      "Epoch [46/50], Batch [44/56], Loss: 1.5843684673309326\n",
      "Epoch [46/50], Batch [46/56], Loss: 1.833423137664795\n",
      "Epoch [46/50], Batch [48/56], Loss: 1.7380716800689697\n",
      "Epoch [46/50], Batch [50/56], Loss: 1.9630718231201172\n",
      "Epoch [46/50], Batch [52/56], Loss: 1.9610706567764282\n",
      "Epoch [46/50], Batch [54/56], Loss: 2.1173036098480225\n",
      "Epoch [46/50], Batch [56/56], Loss: 2.7720446586608887\n",
      "Epoch [46/50] completed, Loss: 2.7720446586608887\n",
      "Epoch [47/50], Batch [2/56], Loss: 1.9128317832946777\n",
      "Epoch [47/50], Batch [4/56], Loss: 1.9090670347213745\n",
      "Epoch [47/50], Batch [6/56], Loss: 1.7714253664016724\n",
      "Epoch [47/50], Batch [8/56], Loss: 2.564518928527832\n",
      "Epoch [47/50], Batch [10/56], Loss: 2.266040086746216\n",
      "Epoch [47/50], Batch [12/56], Loss: 1.7438188791275024\n",
      "Epoch [47/50], Batch [14/56], Loss: 2.1715784072875977\n",
      "Epoch [47/50], Batch [16/56], Loss: 2.266160249710083\n",
      "Epoch [47/50], Batch [18/56], Loss: 1.787379503250122\n",
      "Epoch [47/50], Batch [20/56], Loss: 2.109971046447754\n",
      "Epoch [47/50], Batch [22/56], Loss: 1.8045296669006348\n",
      "Epoch [47/50], Batch [24/56], Loss: 2.725271224975586\n",
      "Epoch [47/50], Batch [26/56], Loss: 1.9509062767028809\n",
      "Epoch [47/50], Batch [28/56], Loss: 2.1423444747924805\n",
      "Epoch [47/50], Batch [30/56], Loss: 1.9260276556015015\n",
      "Epoch [47/50], Batch [32/56], Loss: 1.7417117357254028\n",
      "Epoch [47/50], Batch [34/56], Loss: 2.216106653213501\n",
      "Epoch [47/50], Batch [36/56], Loss: 1.968014121055603\n",
      "Epoch [47/50], Batch [38/56], Loss: 1.988600254058838\n",
      "Epoch [47/50], Batch [40/56], Loss: 2.0619192123413086\n",
      "Epoch [47/50], Batch [42/56], Loss: 2.4404067993164062\n",
      "Epoch [47/50], Batch [44/56], Loss: 1.5757715702056885\n",
      "Epoch [47/50], Batch [46/56], Loss: 1.8311207294464111\n",
      "Epoch [47/50], Batch [48/56], Loss: 1.7325611114501953\n",
      "Epoch [47/50], Batch [50/56], Loss: 1.960152268409729\n",
      "Epoch [47/50], Batch [52/56], Loss: 1.9600138664245605\n",
      "Epoch [47/50], Batch [54/56], Loss: 2.1121301651000977\n",
      "Epoch [47/50], Batch [56/56], Loss: 2.771566867828369\n",
      "Epoch [47/50] completed, Loss: 2.771566867828369\n",
      "Epoch [48/50], Batch [2/56], Loss: 1.9075767993927002\n",
      "Epoch [48/50], Batch [4/56], Loss: 1.9013773202896118\n",
      "Epoch [48/50], Batch [6/56], Loss: 1.7656968832015991\n",
      "Epoch [48/50], Batch [8/56], Loss: 2.5628552436828613\n",
      "Epoch [48/50], Batch [10/56], Loss: 2.2668514251708984\n",
      "Epoch [48/50], Batch [12/56], Loss: 1.7357051372528076\n",
      "Epoch [48/50], Batch [14/56], Loss: 2.1727678775787354\n",
      "Epoch [48/50], Batch [16/56], Loss: 2.2669739723205566\n",
      "Epoch [48/50], Batch [18/56], Loss: 1.7813661098480225\n",
      "Epoch [48/50], Batch [20/56], Loss: 2.107710599899292\n",
      "Epoch [48/50], Batch [22/56], Loss: 1.7998762130737305\n",
      "Epoch [48/50], Batch [24/56], Loss: 2.7295446395874023\n",
      "Epoch [48/50], Batch [26/56], Loss: 1.9453272819519043\n",
      "Epoch [48/50], Batch [28/56], Loss: 2.139582633972168\n",
      "Epoch [48/50], Batch [30/56], Loss: 1.9233946800231934\n",
      "Epoch [48/50], Batch [32/56], Loss: 1.733616590499878\n",
      "Epoch [48/50], Batch [34/56], Loss: 2.2136478424072266\n",
      "Epoch [48/50], Batch [36/56], Loss: 1.9637987613677979\n",
      "Epoch [48/50], Batch [38/56], Loss: 1.9881032705307007\n",
      "Epoch [48/50], Batch [40/56], Loss: 2.057328701019287\n",
      "Epoch [48/50], Batch [42/56], Loss: 2.441941022872925\n",
      "Epoch [48/50], Batch [44/56], Loss: 1.5672756433486938\n",
      "Epoch [48/50], Batch [46/56], Loss: 1.8288865089416504\n",
      "Epoch [48/50], Batch [48/56], Loss: 1.7271466255187988\n",
      "Epoch [48/50], Batch [50/56], Loss: 1.957277536392212\n",
      "Epoch [48/50], Batch [52/56], Loss: 1.9590375423431396\n",
      "Epoch [48/50], Batch [54/56], Loss: 2.106998920440674\n",
      "Epoch [48/50], Batch [56/56], Loss: 2.771096706390381\n",
      "Epoch [48/50] completed, Loss: 2.771096706390381\n",
      "Epoch [49/50], Batch [2/56], Loss: 1.902406930923462\n",
      "Epoch [49/50], Batch [4/56], Loss: 1.893740177154541\n",
      "Epoch [49/50], Batch [6/56], Loss: 1.7600412368774414\n",
      "Epoch [49/50], Batch [8/56], Loss: 2.5611953735351562\n",
      "Epoch [49/50], Batch [10/56], Loss: 2.2676868438720703\n",
      "Epoch [49/50], Batch [12/56], Loss: 1.7276678085327148\n",
      "Epoch [49/50], Batch [14/56], Loss: 2.1739816665649414\n",
      "Epoch [49/50], Batch [16/56], Loss: 2.2678117752075195\n",
      "Epoch [49/50], Batch [18/56], Loss: 1.7754430770874023\n",
      "Epoch [49/50], Batch [20/56], Loss: 2.1054792404174805\n",
      "Epoch [49/50], Batch [22/56], Loss: 1.7952940464019775\n",
      "Epoch [49/50], Batch [24/56], Loss: 2.73380184173584\n",
      "Epoch [49/50], Batch [26/56], Loss: 1.9398140907287598\n",
      "Epoch [49/50], Batch [28/56], Loss: 2.1368589401245117\n",
      "Epoch [49/50], Batch [30/56], Loss: 1.9208288192749023\n",
      "Epoch [49/50], Batch [32/56], Loss: 1.725597858428955\n",
      "Epoch [49/50], Batch [34/56], Loss: 2.2112550735473633\n",
      "Epoch [49/50], Batch [36/56], Loss: 1.9596302509307861\n",
      "Epoch [49/50], Batch [38/56], Loss: 1.9876469373703003\n",
      "Epoch [49/50], Batch [40/56], Loss: 2.0527853965759277\n",
      "Epoch [49/50], Batch [42/56], Loss: 2.44352650642395\n",
      "Epoch [49/50], Batch [44/56], Loss: 1.5588796138763428\n",
      "Epoch [49/50], Batch [46/56], Loss: 1.826719045639038\n",
      "Epoch [49/50], Batch [48/56], Loss: 1.7218269109725952\n",
      "Epoch [49/50], Batch [50/56], Loss: 1.9544477462768555\n",
      "Epoch [49/50], Batch [52/56], Loss: 1.9581406116485596\n",
      "Epoch [49/50], Batch [54/56], Loss: 2.101909875869751\n",
      "Epoch [49/50], Batch [56/56], Loss: 2.770634412765503\n",
      "Epoch [49/50] completed, Loss: 2.770634412765503\n",
      "Epoch [50/50], Batch [2/56], Loss: 1.8973209857940674\n",
      "Epoch [50/50], Batch [4/56], Loss: 1.8861550092697144\n",
      "Epoch [50/50], Batch [6/56], Loss: 1.754457712173462\n",
      "Epoch [50/50], Batch [8/56], Loss: 2.5595390796661377\n",
      "Epoch [50/50], Batch [10/56], Loss: 2.268545627593994\n",
      "Epoch [50/50], Batch [12/56], Loss: 1.719706416130066\n",
      "Epoch [50/50], Batch [14/56], Loss: 2.1752192974090576\n",
      "Epoch [50/50], Batch [16/56], Loss: 2.2686729431152344\n",
      "Epoch [50/50], Batch [18/56], Loss: 1.7696090936660767\n",
      "Epoch [50/50], Batch [20/56], Loss: 2.1032767295837402\n",
      "Epoch [50/50], Batch [22/56], Loss: 1.7907823324203491\n",
      "Epoch [50/50], Batch [24/56], Loss: 2.738041877746582\n",
      "Epoch [50/50], Batch [26/56], Loss: 1.9343663454055786\n",
      "Epoch [50/50], Batch [28/56], Loss: 2.1341731548309326\n",
      "Epoch [50/50], Batch [30/56], Loss: 1.9183295965194702\n",
      "Epoch [50/50], Batch [32/56], Loss: 1.7176549434661865\n",
      "Epoch [50/50], Batch [34/56], Loss: 2.2089266777038574\n",
      "Epoch [50/50], Batch [36/56], Loss: 1.9555089473724365\n",
      "Epoch [50/50], Batch [38/56], Loss: 1.9872310161590576\n",
      "Epoch [50/50], Batch [40/56], Loss: 2.0482888221740723\n",
      "Epoch [50/50], Batch [42/56], Loss: 2.445162534713745\n",
      "Epoch [50/50], Batch [44/56], Loss: 1.5505831241607666\n",
      "Epoch [50/50], Batch [46/56], Loss: 1.8246183395385742\n",
      "Epoch [50/50], Batch [48/56], Loss: 1.7166008949279785\n",
      "Epoch [50/50], Batch [50/56], Loss: 1.9516618251800537\n",
      "Epoch [50/50], Batch [52/56], Loss: 1.957322597503662\n",
      "Epoch [50/50], Batch [54/56], Loss: 2.096862316131592\n",
      "Epoch [50/50], Batch [56/56], Loss: 2.7701785564422607\n",
      "Epoch [50/50] completed, Loss: 2.7701785564422607\n"
     ]
    }
   ],
   "source": [
    "# The nn.embedding take Indices by which it returns vectors\n",
    "\n",
    "\n",
    "# it's common to use embedding size = 100 \n",
    "# embedding neural network takes 2 sizes : Input (No. of vocab since i use one hot encoding )\n",
    "# Hidden layer size : embedding\n",
    "embedding_dim= 100\n",
    "\n",
    "# returns the integer representation of the one hot vectors -> needed by nn.embedding\n",
    "input_indices  = encoded_vocab.toarray()\n",
    "output_indices = encoded_labels.toarray()\n",
    "\n",
    "test_tensor = torch.from_numpy(input_indices).type(torch.long).to(torch.device(\"cuda\"))\n",
    "label_tensor = torch.from_numpy(output_indices).type(torch.float32).to(torch.device(\"cuda\"))\n",
    "\n",
    "# to be able to train the nn.Embedding on your data\n",
    "# we inherit from nn.Module and construct the custom word embedding \n",
    "# what we do : \n",
    "# ONE hot encodes input dimension = Vocab -> Neural network dimension = Embedding ->output to hidden ->  dimension = Labels \n",
    "# use softmax to get what label\n",
    "\n",
    "\n",
    "class CustomWordEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_length, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_length,embedding_dim, device=torch.device(\"cuda\"))\n",
    "        self.hidden_to_output = nn.Linear(embedding_dim, 11, bias= False, device= torch.device(\"cuda\"))\n",
    "  \n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    # this function has a problem\n",
    "    def forward(self, input):\n",
    "        hidden = self.embed(input)\n",
    "\n",
    "        hidden_mean = hidden.mean(dim = 1 )\n",
    "\n",
    "        output = self.hidden_to_output(hidden_mean)\n",
    "        \n",
    "        output = nn.functional.log_softmax(output, dim = -1)\n",
    "       \n",
    "        return output\n",
    "\n",
    "# number of iterations (epoch is a standard way of saying iteration)\n",
    "# each epoch has N(4) batches so the loop should run 400 times\n",
    "epochs =10000\n",
    "\n",
    "dataset = SimpleDataset(test_tensor,label_tensor)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=4 )\n",
    "\n",
    "model = CustomWordEmbedding(vocab_length,100)\n",
    "\n",
    "# stochastic gradient descent\n",
    "optimizer = torch.optim.Adam(model.embed.parameters(), lr = 0.001)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for batch_id, (indices, labels) in enumerate(dataloader):\n",
    "        outputs = model(indices)\n",
    "        \n",
    "        loss = model.loss(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print loss for each batch\n",
    "        if (batch_id + 1) % 2 == 0:  # Print every 2 batches\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}], Batch [{batch_id+1}/{len(dataloader)}], Loss: {loss.item()}\")\n",
    "\n",
    "    # Optionally, print loss for every epoch\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] completed, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"pizza\"\n",
    "hefney = vocab_encoder.transform([[word]])\n",
    "tensor_hefney = torch.from_numpy(hefney.toarray()).type(torch.long).to(torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(tensor_hefney)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.to(torch.device(\"cpu\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('embed.weight',\n",
       "              tensor([[ 1.2993e+00,  1.4934e+00,  3.5305e-01,  ..., -3.7902e-01,\n",
       "                       -6.4480e-02,  5.1436e-01],\n",
       "                      [ 1.0336e-01,  1.5277e+00,  4.8985e-01,  ...,  6.7988e-01,\n",
       "                        1.3882e+00, -4.6104e-01],\n",
       "                      [ 3.9099e-01, -1.9247e+00,  5.9736e-06,  ...,  8.3583e-01,\n",
       "                        2.6491e-01, -4.0906e-01],\n",
       "                      ...,\n",
       "                      [-2.8443e-01,  1.0784e+00,  1.1228e-01,  ..., -1.1314e+00,\n",
       "                       -1.2946e-01,  5.4189e-01],\n",
       "                      [ 1.7681e-01,  9.5952e-01, -7.6338e-01,  ..., -5.5910e-01,\n",
       "                       -1.8051e+00, -1.2685e+00],\n",
       "                      [ 1.7878e+00, -1.2707e-01, -1.3408e+00,  ..., -4.4695e-01,\n",
       "                        1.0022e+00, -4.8933e-01]], device='cuda:0')),\n",
       "             ('hidden_to_output.weight',\n",
       "              tensor([[ 0.0333,  0.0058,  0.0297,  ..., -0.0585,  0.0722,  0.0548],\n",
       "                      [ 0.0732, -0.0500,  0.0236,  ...,  0.0107, -0.0089, -0.0220],\n",
       "                      [ 0.0558,  0.0228, -0.0231,  ...,  0.0600,  0.0273, -0.0904],\n",
       "                      ...,\n",
       "                      [ 0.0780,  0.0719, -0.0409,  ...,  0.0306, -0.0186,  0.0972],\n",
       "                      [-0.0480,  0.0685,  0.0156,  ...,  0.0101,  0.0541, -0.0057],\n",
       "                      [ 0.0640,  0.0263, -0.0904,  ...,  0.0270,  0.0683, -0.0290]],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
