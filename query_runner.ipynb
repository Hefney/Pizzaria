{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-13T16:59:34.679139Z",
     "start_time": "2024-12-13T16:59:32.540062Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from utils_2 import get_vocab, get_tags"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T17:00:40.516645Z",
     "start_time": "2024-12-13T17:00:40.511115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_model_state(model, path):\n",
    "    \"\"\"\n",
    "    Loads the model's parameters into a pre-defined architecture\n",
    "    \"\"\"\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "\n",
    "class NER(nn.Module):\n",
    "  def __init__(self, vocab_size=5, embedding_dim=50, hidden_size=50, n_classes=5):\n",
    "    \"\"\"\n",
    "    The constructor of our NER model\n",
    "    Inputs:\n",
    "    - vacab_size: the number of unique words\n",
    "    - embedding_dim: the embedding dimension\n",
    "    - n_classes: the number of final classes (tags)\n",
    "    \"\"\"\n",
    "    super(NER, self).__init__()\n",
    "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "    self.lstm = nn.LSTM(embedding_dim, hidden_size, batch_first=True, bidirectional=True)\n",
    "    self.dropout = nn.Dropout(p=0.25)\n",
    "    self.linear = nn.Linear(hidden_size * 2, n_classes) # x2 cuz bi-directional\n",
    "    \n",
    "  def forward(self, sentences):\n",
    "    \"\"\"\n",
    "    This function does the forward pass of our model\n",
    "    Inputs:\n",
    "    - sentences: tensor of shape (batch_size, max_length)\n",
    "\n",
    "    Returns:\n",
    "    - final_output: tensor of shape (batch_size, max_length, n_classes)\n",
    "    \"\"\"\n",
    "    embedding = self.embedding(sentences)\n",
    "    lstm, _ = self.lstm(embedding)\n",
    "    dropout = self.dropout(lstm)\n",
    "    final_output = self.linear(dropout)\n",
    "    return final_output"
   ],
   "id": "59fff420368e845a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T17:02:26.564410Z",
     "start_time": "2024-12-13T17:02:26.558915Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vocab    = get_vocab('processed_input/train_vocab.txt')\n",
    "\n",
    "tags_ct  = get_tags('processed_input/train_complex_topping_tags.txt')  # Complex Topping tags\n",
    "tags_pz  = get_tags('processed_input/train_pizza_orders_tags.txt')     # Pizza orders tags\n",
    "tags_dr  = get_tags('processed_input/train_drink_orders_tags.txt')     # Drink orders tags\n",
    "tags_ob  = get_tags('processed_input/train_orders_tags.txt')           # Order boundary tags\n"
   ],
   "id": "20a2a42aac75fb96",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T17:02:41.233538Z",
     "start_time": "2024-12-13T17:02:41.230293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(tags_ct)\n",
    "print(tags_pz)\n",
    "print(tags_dr)\n",
    "print(tags_ob)"
   ],
   "id": "2580418d014633e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'QUANTITY': 0, 'TOPPING': 1, 'TOPPING_S': 2, 'QUANTITY_S': 3, 'NONE': 4}\n",
      "{'TOPPING_S': 0, 'COMPLEX_TOPPING_S': 1, 'NOT_STYLE_S': 2, 'STYLE': 3, 'NUMBER': 4, 'TOPPING': 5, 'SIZE': 6, 'NONE': 7, 'NOT_TOPPING': 8, 'NOT_TOPPING_S': 9, 'NUMBER_S': 10, 'NOT_COMPLEX_TOPPING_S': 11, 'STYLE_S': 12, 'NOT_COMPLEX_TOPPING': 13, 'COMPLEX_TOPPING': 14, 'SIZE_S': 15, 'NOT_STYLE': 16}\n",
      "{'SIZE': 0, 'CONTAINERTYPE': 1, 'DRINKTYPE': 2, 'DRINKTYPE_S': 3, 'NONE': 4, 'CONTAINERTYPE_S': 5, 'VOLUME': 6, 'NUMBER': 7, 'VOLUME_S': 8, 'SIZE_S': 9, 'NUMBER_S': 10}\n",
      "{'DRINKORDER': 0, 'DRINKORDER_S': 1, 'PIZZAORDER': 2, 'PIZZAORDER_S': 3, 'NONE': 4}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T17:32:34.873292Z",
     "start_time": "2024-12-13T17:32:34.786019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_boundary    = NER(embedding_dim=70, hidden_size=200, n_classes=len(tags_ob), vocab_size=len(vocab))\n",
    "model_pizza_order = NER(embedding_dim=70, hidden_size=500, n_classes=len(tags_pz), vocab_size=len(vocab))\n",
    "model_drink_order = NER(embedding_dim=70, hidden_size=500, n_classes=len(tags_dr), vocab_size=len(vocab))\n",
    "model_complex     = NER(embedding_dim=70, hidden_size=500, n_classes=len(tags_ct), vocab_size=len(vocab))\n",
    "\n",
    "load_model_state(model_boundary, \"models/order_boundary_x95.3.pth\")\n",
    "load_model_state(model_pizza_order, \"models/pizza_order_x94.4.pth\")\n",
    "load_model_state(model_drink_order, \"models/drink_order_x100.0.pth\")\n",
    "load_model_state(model_complex, \"models/complex_x100.0.pth\")\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "model_boundary.to(device)\n",
    "model_pizza_order.to(device)\n",
    "model_drink_order.to(device)\n",
    "model_complex.to(device)"
   ],
   "id": "f1a8a4f6a8931eb4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xAbdoMo\\AppData\\Local\\Temp\\ipykernel_32144\\600413792.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NER(\n",
       "  (embedding): Embedding(307, 70)\n",
       "  (lstm): LSTM(70, 500, batch_first=True, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       "  (linear): Linear(in_features=1000, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T17:32:36.700033Z",
     "start_time": "2024-12-13T17:32:36.695062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tags_inverse(tags):\n",
    "    inv_tags = {}\n",
    "    for tag, value in tags.items():\n",
    "        inv_tags[value] = tag\n",
    "    return inv_tags\n",
    "\n",
    "inv_tags_ct = tags_inverse(tags_ct)\n",
    "inv_tags_pz = tags_inverse(tags_pz)\n",
    "inv_tags_dr = tags_inverse(tags_dr)\n",
    "inv_tags_ob = tags_inverse(tags_ob)\n",
    "\n",
    "print(inv_tags_ct)\n",
    "print(inv_tags_pz)\n",
    "print(inv_tags_dr)\n",
    "print(inv_tags_ob)"
   ],
   "id": "3ab663ded4987b64",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'QUANTITY', 1: 'TOPPING', 2: 'TOPPING_S', 3: 'QUANTITY_S', 4: 'NONE'}\n",
      "{0: 'TOPPING_S', 1: 'COMPLEX_TOPPING_S', 2: 'NOT_STYLE_S', 3: 'STYLE', 4: 'NUMBER', 5: 'TOPPING', 6: 'SIZE', 7: 'NONE', 8: 'NOT_TOPPING', 9: 'NOT_TOPPING_S', 10: 'NUMBER_S', 11: 'NOT_COMPLEX_TOPPING_S', 12: 'STYLE_S', 13: 'NOT_COMPLEX_TOPPING', 14: 'COMPLEX_TOPPING', 15: 'SIZE_S', 16: 'NOT_STYLE'}\n",
      "{0: 'SIZE', 1: 'CONTAINERTYPE', 2: 'DRINKTYPE', 3: 'DRINKTYPE_S', 4: 'NONE', 5: 'CONTAINERTYPE_S', 6: 'VOLUME', 7: 'NUMBER', 8: 'VOLUME_S', 9: 'SIZE_S', 10: 'NUMBER_S'}\n",
      "{0: 'DRINKORDER', 1: 'DRINKORDER_S', 2: 'PIZZAORDER', 3: 'PIZZAORDER_S', 4: 'NONE'}\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T17:32:38.729063Z",
     "start_time": "2024-12-13T17:32:38.719490Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def feed_model(model, query, inv_tags):\n",
    "    s = [vocab[token] if token in vocab\n",
    "                 else vocab['<UNK>']\n",
    "                 for token in query.split(' ') if token != '']\n",
    "    x_tensor = torch.tensor(s)\n",
    "    output = model.forward(x_tensor.to(device))\n",
    "    output = torch.argmax(output, dim=-1).to(\"cpu\")\n",
    "    return [inv_tags[x.item()] for x in output]\n",
    "\n",
    "feed_model(model_boundary, \"can i have one pizza\", inv_tags_ob)    "
   ],
   "id": "e1970f2bd16170ac",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NONE', 'NONE', 'NONE', 'PIZZAORDER_S', 'PIZZAORDER']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T18:05:02.544576Z",
     "start_time": "2024-12-13T18:05:02.527624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_complex(order):\n",
    "    words = [token for token in order.split(' ') if token != '']\n",
    "    order_result = feed_model(model_complex, order, inv_tags_ct)\n",
    "    result = \"\"\n",
    "    index = 0\n",
    "    \n",
    "    TAGS_STARTERS = [\"TOPPING_S\", \"QUANTITY_S\"]\n",
    "    TAGS_CONT     = [\"TOPPING\"  , \"QUANTITY\"  ]\n",
    "    while index < len(order_result):  # len(order_result) == len(words)\n",
    "        found = False\n",
    "        for tag_s, tag in zip(TAGS_STARTERS, TAGS_CONT):\n",
    "            if order_result[index] == tag_s:\n",
    "                found = True\n",
    "                content = [words[index]]\n",
    "                index = index + 1\n",
    "                while index < len(order_result) and order_result[index] == tag:\n",
    "                    content = content + [words[index]]\n",
    "                    index = index + 1\n",
    "                result += f\"({tag} {' '.join(content)}) \"\n",
    "                break\n",
    "        if not found:\n",
    "            result += words[index] + \" \"\n",
    "            index = index + 1\n",
    "    \n",
    "    return result\n",
    "\n",
    "def run_pizza_order(order):\n",
    "    words = [token for token in order.split(' ') if token != '']\n",
    "    order_result = feed_model(model_pizza_order, order, inv_tags_pz)\n",
    "    result = \"\"\n",
    "    # print(order_result)\n",
    "    index = 0\n",
    "    \n",
    "    NORMAL_TAGS_STARTERS = [\"TOPPING_S\", \"STYLE_S\", \"SIZE_S\", \"NUMBER_S\"]\n",
    "    NORMAL_TAGS_CONT     = [\"TOPPING\"  , \"STYLE\"  , \"SIZE\"  , \"NUMBER\"]\n",
    "    \n",
    "    NOT_TAGS_STARTERS    = [\"NOT_TOPPING_S\", \"NOT_STYLE_S\", \"NOT_SIZE_S\", \"NOT_NUMBER_S\"]   # last two doesn't exist but aahhh whatever xD\n",
    "    NOT_TAGS_CONT        = [\"NOT_TOPPING\"  , \"NOT_STYLE\"  , \"NOT_SIZE\"  , \"NOT_NUMBER\"]     # I'll keep it just in case the model is tripping or something :)\n",
    "    while index < len(order_result):  # len(order_result) == len(words)\n",
    "        found = False\n",
    "        for tag_s, tag in zip(NORMAL_TAGS_STARTERS, NORMAL_TAGS_CONT):\n",
    "            if order_result[index] == tag_s:\n",
    "                found = True\n",
    "                content = [words[index]]\n",
    "                index = index + 1\n",
    "                while index < len(order_result) and order_result[index] == tag:\n",
    "                    content = content + [words[index]]\n",
    "                    index = index + 1\n",
    "                result += f\"({tag} {' '.join(content)}) \"\n",
    "                break\n",
    "        if found:\n",
    "           continue\n",
    "        \n",
    "        for tag_s, tag in zip(NOT_TAGS_STARTERS, NOT_TAGS_CONT):\n",
    "            if order_result[index] == tag_s:\n",
    "                found = True\n",
    "                content = [words[index]]\n",
    "                index = index + 1\n",
    "                while index < len(order_result) and order_result[index] == tag:\n",
    "                    content = content + [words[index]]\n",
    "                    index = index + 1\n",
    "                result += f\"(NOT ({tag[4:]} {' '.join(content)}) ) \"\n",
    "                break\n",
    "                \n",
    "        if found:\n",
    "           continue\n",
    "            \n",
    "        # special case: COMPLEX_TOPPING_S & NOT_COMPLEX_TOPPING_S\n",
    "        if \"COMPLEX_TOPPING_S\" in order_result[index]:\n",
    "            found = True\n",
    "            negated = \"NOT\" in order_result[index]\n",
    "            content = [words[index]]\n",
    "            index = index + 1\n",
    "            while index < len(order_result) and \"COMPLEX_TOPPING\" in order_result[index]:\n",
    "                content = content + [words[index]]\n",
    "                index = index + 1\n",
    "            val = run_complex(' '.join(content))\n",
    "            if negated:\n",
    "                result += f\"(NOT (COMPLEX {val}) ) \"\n",
    "            else:\n",
    "                result += f\"(COMPLEX {val}) \"\n",
    "        if found:\n",
    "           continue\n",
    "        result += words[index] + \" \"\n",
    "        index = index + 1\n",
    "    \n",
    "    return result\n",
    "\n",
    "def run_drink_order(order):\n",
    "    words = [token for token in order.split(' ') if token != '']\n",
    "    order_result = feed_model(model_drink_order, order, inv_tags_dr)\n",
    "    result = \"\"\n",
    "    index = 0\n",
    "    \n",
    "    TAGS_STARTERS = [\"SIZE_S\", \"VOLUME_S\", \"NUMBER_S\", \"DRINKTYPE_S\", \"CONTAINERTYPE_S\"]\n",
    "    TAGS_CONT     = [\"SIZE\"  , \"VOLUME\"  , \"NUMBER\"  , \"DRINKTYPE\"  , \"CONTAINERTYPE\"]\n",
    "    while index < len(order_result):  # len(order_result) == len(words)\n",
    "        found = False\n",
    "        for tag_s, tag in zip(TAGS_STARTERS, TAGS_CONT):\n",
    "            if order_result[index] == tag_s:\n",
    "                found = True\n",
    "                content = [words[index]]\n",
    "                index = index + 1\n",
    "                while index < len(order_result) and order_result[index] == tag:\n",
    "                    content = content + [words[index]]\n",
    "                    index = index + 1\n",
    "                result += f\"({tag} {' '.join(content)}) \"\n",
    "                break\n",
    "        if not found:\n",
    "            result += words[index] + \" \"\n",
    "            index = index + 1\n",
    "    \n",
    "    return result\n",
    "\n",
    "def run_order(order):\n",
    "    words = [token for token in order.split(' ') if token != '']\n",
    "    order_result = feed_model(model_boundary, order, inv_tags_ob)\n",
    "    result = \"\"\n",
    "    index = 0\n",
    "    while index < len(order_result):  # len(order_result) == len(words)\n",
    "        if order_result[index] in 'PIZZAORDER_S':  # read a pizza order\n",
    "            order = [words[index]]\n",
    "            index = index + 1\n",
    "            while index < len(order_result) and order_result[index] == 'PIZZAORDER':\n",
    "                order = order + [words[index]]\n",
    "                index = index + 1\n",
    "            \n",
    "            result += f\"(PIZZAORDER {run_pizza_order(' '.join(order))}) \"\n",
    "        elif order_result[index] in 'DRINKORDER_S':  # read a drink order\n",
    "            order = [words[index]]\n",
    "            index = index + 1\n",
    "            while index < len(order_result) and order_result[index] == 'DRINKORDER':\n",
    "                order = order + [words[index]]\n",
    "                index = index + 1\n",
    "                \n",
    "            result += f\"(DRINKORDER {run_drink_order(' '.join(order))}) \"\n",
    "        else:\n",
    "            result += words[index] + \" \"\n",
    "            index = index + 1\n",
    "    return result\n",
    "    \n",
    "def run_query(query):\n",
    "    query = query.lower()\n",
    "    return f\"(ORDER {run_order(query)})\"\n",
    "\n",
    "\n",
    "print(run_query(\"i want to order one pepperoni pizza with ham and without onions and one coke\"))"
   ],
   "id": "9c220327f1d8e7fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ORDER i want to order (PIZZAORDER (NUMBER one) (TOPPING pepperoni) pizza with (TOPPING ham) and without (NOT (TOPPING onions) ) ) and (DRINKORDER (NUMBER one) (DRINKTYPE coke) ) )\n"
     ]
    }
   ],
   "execution_count": 55
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
