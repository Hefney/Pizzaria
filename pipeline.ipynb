{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from 'c:\\\\Users\\\\abdo_\\\\Downloads\\\\programs\\\\NLP\\\\Pizzaria\\\\utils.py'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from nltk.tokenize import MWETokenizer\n",
    "import importlib\n",
    "import re\n",
    "from word2number import w2n\n",
    "import pickle\n",
    "importlib.reload(utils)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1 READ THE DATA\n",
    "read_dataset: takes path to JSON file that has sentences, _.EXR, _.TOP, _.TOP_DECOUPLED\n",
    "and returns them as pandas.Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, parsed_tree, structured_sentence, decoupled_structured_sentence = utils.read_dataset(\"./PIZZA_train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't need them so free the data\n",
    "del parsed_tree\n",
    "del decoupled_structured_sentence\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2: Parse data and extract labels\n",
    "In this step we build our Multiword expressions, extract the labels of every token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do this if u didn't read the pizza_train.json above\n",
    "structured_sentence = pd.read_csv(\"TOP.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do this if u read the TOP.csv\n",
    "structured_sentence = structured_sentence.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pizza_orders, drink_orders, none_words = utils.extract_pizza_drinks(structured_sentence.copy())\n",
    "\n",
    "none_words = none_words.drop_duplicates()\n",
    "\n",
    "none_words = utils.pre_text_normalization(none_words)\n",
    "\n",
    "none_words = none_words.reset_index(drop=True)\n",
    "\n",
    "nones, _ = utils.tokenization(none_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pizza_nodes, drink_nodes = utils.extract_nodes(pizza_orders,drink_orders)\n",
    "pizza_nodes, drink_nodes = utils.clean_extracted_nodes(pizza_nodes, drink_nodes)\n",
    "pizza_number, pizza_size, pizza_none, topping , quantity, style = pizza_nodes\n",
    "drink_number, drink_size, drink_none, drink_type, container_type, volume = drink_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = pd.concat([pizza_number,drink_number])\n",
    "size = pd.concat([pizza_size,drink_size])\n",
    "none = pd.concat([pizza_none,drink_none])\n",
    "number.drop_duplicates(inplace=True)\n",
    "size.drop_duplicates(inplace=True)\n",
    "none.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will treat the volume differently than other nodes to make sure i take into consideration the measuring units only\n",
    "vocab, _ = utils.tokenization(volume)\n",
    "volume_vocab = set()\n",
    "for word in vocab:\n",
    "    try:\n",
    "        _ = w2n.word_to_num(word)\n",
    "        number[-1] = word\n",
    "        number.reset_index(drop=True,inplace=True)\n",
    "        number.drop_duplicates(inplace=True)\n",
    "    except ValueError:\n",
    "        volume_vocab.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_vocab = pd.Series(list(volume_vocab))\n",
    "volume_vocab.to_csv(f\"./labels/volume.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = [number, size, none, topping, quantity, style, drink_type, container_type, volume]\n",
    "csv_file_names = [\"number\", \"size\", \"none\",\"topping\",\"quantity\",\"style\",\"drink_type\",\"container_type\"]\n",
    "# merge nones that came from inside the PIZZAORDER, DRINKORDER and what u got from outside them\n",
    "none_vocab = nones\n",
    "mwe =[]\n",
    "for label, csv in zip(labels, csv_file_names):\n",
    "    if csv != \"none\":\n",
    "        _, tokens = utils.tokenization(label)\n",
    "        tokens.drop_duplicates(inplace=True)\n",
    "        vocab = set()\n",
    "        for col in tokens.columns:\n",
    "            tokens.loc[tokens[col] == 0,col] = \"\"\n",
    "        tokens = tokens.to_numpy().tolist()\n",
    "        for i,token_list in enumerate(tokens):\n",
    "            while \"\" in token_list:\n",
    "                token_list.remove(\"\")\n",
    "            if len(token_list) == 1:\n",
    "                vocab.add(token_list[0])\n",
    "            else:\n",
    "                mwe.append(tuple(token_list))\n",
    "                string = \"_\".join(token_list)\n",
    "                string = re.sub(\"_+$\",\"\",string)\n",
    "                vocab.add(string)\n",
    "    else:\n",
    "        vocab, _ = utils.tokenization(label)\n",
    "        vocab.update(none_vocab)\n",
    "\n",
    "    vocab = pd.Series(list(vocab))\n",
    "    vocab.to_csv(f\"./labels/{csv}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the state of the MWETOKENIZER to be used when processing the sentences\n",
    "tokenizer = MWETokenizer(mwe)\n",
    "with open(\"MWE_TOKENS.pkl\", 'wb') as file:\n",
    "    pickle.dump(tokenizer,file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del vocab\n",
    "del labels\n",
    "del csv_file_names\n",
    "del pizza_nodes\n",
    "del pizza_orders\n",
    "del drink_nodes\n",
    "del drink_orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# STEP 3 : preprocess data\n",
    "##### What we should take into consideration? \n",
    "1- Word Normalization  \n",
    "2- Word Tokenization  \n",
    "Why we won't use Sentence segmentation?  \n",
    "It's useless, orders are one sentence question no clear punctuation exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZATION\n",
    "normalized_sentence = utils.pre_text_normalization(sentences.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization\n",
    "vocab, tokenized_sentences = utils.tokenization(normalized_sentence,tokenizesentences=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint: Normalization and tokenization of sentences\n",
    "vocab_as_series = pd.Series(list(vocab))\n",
    "vocab_as_series.to_csv(\"vocab.csv\",index=False)\n",
    "tokenized_sentences.to_csv(\"tokenized_sentences.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del vocab\n",
    "del tokenized_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 4: Encode The tokens and label them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, vocab_encoder, label_encoder = utils.create_labeled_vocab(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bbq_pulled_pork']\n",
      "['topping']\n"
     ]
    }
   ],
   "source": [
    "# made sure that the encoding is correct\n",
    "print(vocab_encoder.categories_[0][([vocab[vocab[\"tokens\"] == \"bbq_pulled_pork\"].loc[vocab[vocab[\"tokens\"] == \"bbq_pulled_pork\"].index[0],\"encoded_tokens\"]])])\n",
    "print(label_encoder.categories_[0][([vocab[vocab[\"tokens\"] == \"bbq_pulled_pork\"].loc[vocab[vocab[\"tokens\"] == \"bbq_pulled_pork\"].index[0],\"encoded_labels\"]])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentences = pd.read_csv(\"tokenized_sentences.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "convertor = utils.conversions(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_as_ids = tokenized_sentences.map(convertor.word2id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_as_ids = tokenized_sentences.map(convertor.word2labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from here on screw Pandas we only work with numpy, and tensors\n",
    "tokens_ids_as_numpy = tokens_as_ids.to_numpy()\n",
    "tokens_labels_as_numpy = labels_as_ids.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tokenized_sentences\n",
    "del tokens_as_ids\n",
    "del labels_as_ids\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check i did encode correctly:\n",
    "encode_test = tokens_ids_as_numpy[0][~np.isnan(tokens_ids_as_numpy[0])] \n",
    "series = vocab[vocab[\"tokens\"] == vocab_encoder.categories_[0][int(tokens_ids_as_numpy[0][3])] ]\n",
    "\n",
    "index = series.index[0]\n",
    "\n",
    "series1, series2 = series.loc[index,\"encoded_labels\"] , series.loc[index,\"encoded_tokens\"] \n",
    "\n",
    "print(vocab_encoder.categories_[0][series2])\n",
    "print(label_encoder.categories_[0][series1])\n",
    "# print(len(tokenized_sentences.loc[0]) == len(tokenized_sentences.loc[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the memory will be bad when we transform the numpy to tensor\n",
    "# we need to split them and save them on disk so we can load batches when we train\n",
    "tokens_batches = np.array_split(tokens_ids_as_numpy,10)\n",
    "labels_batches = np.array_split(tokens_labels_as_numpy,10)\n",
    "del tokens_ids_as_numpy\n",
    "del tokens_labels_as_numpy\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(tokens_batches):\n",
    "    tensor_batch = torch.from_numpy(batch).type(torch.float32)\n",
    "    torch.save(tensor_batch,f\"./tokens_tensors/tokens_batch_{i}.pt\")\n",
    "for i, batch in enumerate(labels_batches):\n",
    "    tensor_batch = torch.from_numpy(batch).type(torch.float32)\n",
    "    torch.save(tensor_batch,f\"./labels_tensors/labels_batch_{i}.pt\")\n",
    "del tensor_batch\n",
    "del tokens_batches\n",
    "del labels_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 5: MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine what to run my tensors on\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# my one hot encoders DETERMINSTIC ON WHAT CRITERIA I WILL TRAIN ON\n",
    "input_size = vocab.shape[0]\n",
    "# this is a parameter \n",
    "hidden_size = 300\n",
    "# output : num of classes\n",
    "num_classes = 11\n",
    "# num of trials (epochs)\n",
    "epochs = 10\n",
    "# Batch size = ? \n",
    "batch_size = 10\n",
    "# learning_rate\n",
    "lr = 0.01\n",
    "\n",
    "# num_layers in RNN default is 1 (increasing layers improve result but worsen the time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# What is the model i will use\n",
    "model = utils.RNN(input_size,num_classes,hidden_size)\n",
    "# loss criteria here i use CEloss\n",
    "loss_criterion = utils.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "# stochastic gradient descent\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr)\n",
    "# they say decaying learning rate is better than fixed one so i will use learning rate scheduler\n",
    "lambdalr = lambda epoch: epoch / 10\n",
    "scheduler = lr_scheduler.LambdaLR(optimizer,lambdalr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [5, 105]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 52\u001b[0m\n\u001b[0;32m     50\u001b[0m         all_preds\u001b[38;5;241m.\u001b[39mextend(preds\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mflatten())\n\u001b[0;32m     51\u001b[0m         all_labels\u001b[38;5;241m.\u001b[39mextend(torch\u001b[38;5;241m.\u001b[39margmax(labels,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mflatten())\n\u001b[1;32m---> 52\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_preds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms Accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy)\n\u001b[0;32m     56\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:231\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    229\u001b[0m xp, _, device \u001b[38;5;241m=\u001b[39m get_namespace_and_device(y_true, y_pred, sample_weight)\n\u001b[0;32m    230\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 231\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:103\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    102\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred)\n\u001b[1;32m--> 103\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    105\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [5, 105]"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(10):\n",
    "    \n",
    "    for i in range(9):\n",
    "        tokens = torch.load(f\"./tokens_tensors/tokens_batch_{i}.pt\",weights_only=True).type(torch.int64)\n",
    "        labels = torch.load(f\"./labels_tensors/labels_batch_{i}.pt\",weights_only=True).type(torch.int64)\n",
    "\n",
    "        dataset = utils.SimpleDataset(tokens,labels)\n",
    "        data = DataLoader(dataset,batch_size=batch_size,shuffle=True)\n",
    "        \n",
    "        del tokens\n",
    "\n",
    "        model.train()\n",
    "        \n",
    "        for input_tensors, label_tensors in data:\n",
    "            \n",
    "            input_tensors = input_tensors.to(device)\n",
    "            \n",
    "            label_tensors = label_tensors.to(device)\n",
    "           \n",
    "            out_tensor = model(input_tensors)\n",
    "            \n",
    "            loss = loss_criterion(out_tensor.view(-1,out_tensor.shape[-1]),label_tensors.view(-1))\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "        # Here should be the evaluation after every epoch\n",
    "        # no grad so that pytorch doesn't insert it in his calculations\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        with torch.no_grad():\n",
    "            # this is a hold-k evaluation (where we hold k from training set and evaluate based on it )\n",
    "            # till i parse the evaluation\n",
    "            tokens = torch.load(f\"./tokens_tensors/tokens_batch_{9}.pt\",weights_only=True).type(torch.int)\n",
    "            labels = torch.load(f\"./labels_tensors/labels_batch_{9}.pt\",weights_only=True).type(torch.int)\n",
    "    \n",
    "            for inputs, labels in data:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                    # Forward pass\n",
    "                    outputs = model(inputs)\n",
    "\n",
    "            # Get predictions\n",
    "            preds = torch.argmax(outputs, dim=2)  # Shape: (batch_size, seq_length, features) dim = 2 : features\n",
    "\n",
    "            # Flatten predictions and labels\n",
    "            all_preds.extend(preds.cpu().numpy().flatten())\n",
    "            all_labels.extend(labels.cpu().numpy().flatten())\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "        print(f\"epoch {epoch}'s Accuracy:\", accuracy)\n",
    "\n",
    "    scheduler.step()\n",
    "    print(f\"epoch {epoch}:, loss ={loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
